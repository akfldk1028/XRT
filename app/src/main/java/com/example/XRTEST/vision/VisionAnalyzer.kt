package com.example.XRTEST.vision

import android.graphics.Bitmap
import android.util.Base64
import android.util.Log
import kotlinx.coroutines.*
import kotlinx.coroutines.flow.*
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONArray
import org.json.JSONObject
import java.io.ByteArrayOutputStream
import java.io.IOException
import java.util.concurrent.TimeUnit

/**
 * Vision Analyzer using OpenAI Chat Completions API with GPT-4V
 * Provides actual image recognition and analysis capabilities
 */
class VisionAnalyzer(
    private val apiKey: String,
    private val onAnalysisResult: (String) -> Unit,
    private val onError: (String) -> Unit
) {
    companion object {
        private const val TAG = "VisionAnalyzer"
        private const val CHAT_API_URL = "https://api.openai.com/v1/chat/completions"
        private const val VISION_MODEL = "gpt-4.1-mini" // üöÄ GPT-4.1-mini: 50% faster latency!
        private const val MAX_IMAGE_SIZE = 384  // üéØ Balance: speed + accuracy
        private const val JPEG_QUALITY = 70     // üéØ Balance: speed + quality
        private const val REQUEST_TIMEOUT_SECONDS = 8L  // üéØ GPT-4.1-mini optimized
        
        // Analysis modes
        const val MODE_GENERAL = "general"
        const val MODE_OBJECT_DETECTION = "object"
        const val MODE_TEXT_READING = "text"
        const val MODE_COLOR_ANALYSIS = "color"
        const val MODE_SCENE_UNDERSTANDING = "scene"
        
        // üöÄ Ultra-fast optimization settings
        const val ULTRA_FAST_MAX_TOKENS = 80   // üéØ Balance: speed + detail
        const val ULTRA_FAST_QUALITY = 80     // üöÄ Good balance speed/quality
    }
    
    private val client = OkHttpClient.Builder()
        .connectTimeout(REQUEST_TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .readTimeout(REQUEST_TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .writeTimeout(REQUEST_TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .build()
    
    private val coroutineScope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    
    // State management
    private val _isAnalyzing = MutableStateFlow(false)
    val isAnalyzing: StateFlow<Boolean> = _isAnalyzing.asStateFlow()
    
    private val _lastAnalysisTime = MutableStateFlow(0L)
    val lastAnalysisTime: StateFlow<Long> = _lastAnalysisTime.asStateFlow()
    
    // Cache for recent analyses
    private val analysisCache = mutableMapOf<String, AnalysisResult>()
    private val cacheExpirationMs = 30000L // 30 seconds
    
    data class AnalysisResult(
        val result: String,
        val timestamp: Long,
        val mode: String
    )
    
    /**
     * Analyze an image with a specific prompt
     * @param bitmap The image to analyze
     * @param prompt Custom prompt for the analysis
     * @param mode Analysis mode (general, object, text, color, scene)
     * @param useKorean Whether to respond in Korean
     */
    /**
     * üöÄ ULTRA-FAST: Analyze image from Base64 string directly (skips Bitmap conversion)
     */
    fun analyzeImageBase64(
        base64Image: String,
        prompt: String? = null,
        mode: String = MODE_GENERAL,
        useKorean: Boolean = true
    ) {
        coroutineScope.launch {
            try {
                _isAnalyzing.value = true
                Log.d(TAG, "üöÄ ULTRA-FAST Base64 analysis - Mode: $mode, Korean: $useKorean")
                
                val imageHash = base64Image.hashCode().toString()
                
                // Check cache
                analysisCache[imageHash]?.let { cached ->
                    if (System.currentTimeMillis() - cached.timestamp < cacheExpirationMs &&
                        cached.mode == mode) {
                        Log.d(TAG, "Using cached analysis result")
                        onAnalysisResult(cached.result)
                        _isAnalyzing.value = false
                        return@launch
                    }
                }
                
                // Create ultra-fast optimized prompts
                val systemPrompt = createUltraFastSystemPrompt(mode, useKorean)
                val userPrompt = prompt ?: createUltraFastPrompt(mode, useKorean)
                
                // Build ultra-fast API request
                val requestBody = buildUltraFastVisionRequest(base64Image, systemPrompt, userPrompt)
                
                // Make the API call
                val request = Request.Builder()
                    .url(CHAT_API_URL)
                    .addHeader("Authorization", "Bearer $apiKey")
                    .addHeader("Content-Type", "application/json")
                    .post(requestBody.toRequestBody("application/json".toMediaType()))
                    .build()
                
                client.newCall(request).execute().use { response ->
                    if (!response.isSuccessful) {
                        val errorBody = response.body?.string() ?: "Unknown error"
                        Log.e(TAG, "API request failed: ${response.code} - $errorBody")
                        onError("Vision analysis failed: ${response.code}")
                        return@use
                    }
                    
                    // Parse the response
                    val responseBody = response.body?.string() ?: ""
                    val jsonResponse = JSONObject(responseBody)
                    
                    // Extract the analysis result
                    val choices = jsonResponse.getJSONArray("choices")
                    if (choices.length() > 0) {
                        val message = choices.getJSONObject(0).getJSONObject("message")
                        val content = message.getString("content")
                        
                        Log.d(TAG, "üöÄ Ultra-fast analysis successful: ${content.take(100)}...")
                        
                        // Cache the result
                        analysisCache[imageHash] = AnalysisResult(
                            result = content,
                            timestamp = System.currentTimeMillis(),
                            mode = mode
                        )
                        
                        _lastAnalysisTime.value = System.currentTimeMillis()
                        onAnalysisResult(content)
                    } else {
                        Log.e(TAG, "No choices in API response")
                        onError("No analysis result received")
                    }
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "Ultra-fast analysis error: ${e.message}", e)
                onError("Analysis failed: ${e.message}")
            } finally {
                _isAnalyzing.value = false
            }
        }
    }
    
    fun analyzeImage(
        bitmap: Bitmap,
        prompt: String? = null,
        mode: String = MODE_GENERAL,
        useKorean: Boolean = true
    ) {
        coroutineScope.launch {
            try {
                _isAnalyzing.value = true
                Log.d(TAG, "Starting image analysis - Mode: $mode, Korean: $useKorean")
                
                // Convert bitmap to base64
                val base64Image = bitmapToBase64(bitmap)
                val imageHash = base64Image.hashCode().toString()
                
                // Check cache
                analysisCache[imageHash]?.let { cached ->
                    if (System.currentTimeMillis() - cached.timestamp < cacheExpirationMs &&
                        cached.mode == mode) {
                        Log.d(TAG, "Using cached analysis result")
                        onAnalysisResult(cached.result)
                        _isAnalyzing.value = false
                        return@launch
                    }
                }
                
                // Create system and user prompts based on mode and language
                val systemPrompt = createSystemPrompt(mode, useKorean)
                val userPrompt = prompt ?: createDefaultPrompt(mode, useKorean)
                
                // Build the API request with ultra-fast optimizations
                val requestBody = buildUltraFastVisionRequest(base64Image, systemPrompt, userPrompt)
                
                // Make the API call
                val request = Request.Builder()
                    .url(CHAT_API_URL)
                    .addHeader("Authorization", "Bearer $apiKey")
                    .addHeader("Content-Type", "application/json")
                    .post(requestBody.toRequestBody("application/json".toMediaType()))
                    .build()
                
                client.newCall(request).execute().use { response ->
                    if (!response.isSuccessful) {
                        val errorBody = response.body?.string() ?: "Unknown error"
                        Log.e(TAG, "API request failed: ${response.code} - $errorBody")
                        onError("Vision analysis failed: ${response.code}")
                        return@use
                    }
                    
                    // Parse the response
                    val responseBody = response.body?.string() ?: ""
                    val jsonResponse = JSONObject(responseBody)
                    
                    // Extract the analysis result
                    val choices = jsonResponse.getJSONArray("choices")
                    if (choices.length() > 0) {
                        val message = choices.getJSONObject(0).getJSONObject("message")
                        val content = message.getString("content")
                        
                        Log.d(TAG, "Analysis successful: ${content.take(200)}...")
                        Log.d(TAG, "üéØ VisionAnalyzer: About to call onAnalysisResult callback...")
                        
                        // Cache the result
                        analysisCache[imageHash] = AnalysisResult(
                            result = content,
                            timestamp = System.currentTimeMillis(),
                            mode = mode
                        )
                        
                        // Update last analysis time
                        _lastAnalysisTime.value = System.currentTimeMillis()
                        
                        // Return the result
                        onAnalysisResult(content)
                        Log.d(TAG, "üéØ VisionAnalyzer: onAnalysisResult callback completed!")
                    } else {
                        Log.e(TAG, "No choices in API response")
                        onError("No analysis result received")
                    }
                }
                
            } catch (e: IOException) {
                Log.e(TAG, "Network error during analysis", e)
                onError("Network error: ${e.message}")
            } catch (e: Exception) {
                Log.e(TAG, "Error during image analysis", e)
                onError("Analysis failed: ${e.message}")
            } finally {
                _isAnalyzing.value = false
            }
        }
    }
    
    /**
     * Analyze image with focus on specific objects
     */
    fun analyzeObjectsInImage(bitmap: Bitmap, useKorean: Boolean = true) {
        val prompt = if (useKorean) {
            "Ïù¥ Ïù¥ÎØ∏ÏßÄÏóêÏÑú Î≥¥Ïù¥Îäî Î™®Îì† Î¨ºÏ≤¥Î•º ÏûêÏÑ∏Ìûà ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî. Í∞Å Î¨ºÏ≤¥Ïùò ÏÉâÏÉÅ, ÌÅ¨Í∏∞, ÏúÑÏπòÎ•º Ìè¨Ìï®Ìï¥Ï£ºÏÑ∏Ïöî."
        } else {
            "Describe all objects visible in this image in detail, including their colors, sizes, and positions."
        }
        analyzeImage(bitmap, prompt, MODE_OBJECT_DETECTION, useKorean)
    }
    
    /**
     * Analyze colors in the image
     */
    fun analyzeColorsInImage(bitmap: Bitmap, useKorean: Boolean = true) {
        val prompt = if (useKorean) {
            "Ïù¥ Ïù¥ÎØ∏ÏßÄÏùò Ï£ºÏöî ÏÉâÏÉÅÎì§ÏùÑ Ï†ïÌôïÌûà ÏãùÎ≥ÑÌïòÍ≥† ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî. Í∞Å Î¨ºÏ≤¥Ïùò Ïã§Ï†ú ÏÉâÏÉÅÏùÑ Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
        } else {
            "Identify and describe the main colors in this image accurately. Specify the actual color of each object."
        }
        analyzeImage(bitmap, prompt, MODE_COLOR_ANALYSIS, useKorean)
    }
    
    /**
     * Read text from the image
     */
    fun readTextFromImage(bitmap: Bitmap, useKorean: Boolean = true) {
        val prompt = if (useKorean) {
            "Ïù¥ Ïù¥ÎØ∏ÏßÄÏóêÏÑú Î≥¥Ïù¥Îäî Î™®Îì† ÌÖçÏä§Ìä∏Î•º ÏùΩÍ≥† Í∑∏ ÎÇ¥Ïö©ÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
        } else {
            "Read all text visible in this image and tell me what it says."
        }
        analyzeImage(bitmap, prompt, MODE_TEXT_READING, useKorean)
    }
    
    /**
     * Understand the scene context
     */
    fun understandScene(bitmap: Bitmap, useKorean: Boolean = true) {
        val prompt = if (useKorean) {
            "Ïù¥ Ïû•Î©¥Ïù¥ Ïñ¥ÎîîÏù∏ÏßÄ, Î¨¥ÏóáÏù¥ ÏùºÏñ¥ÎÇòÍ≥† ÏûàÎäîÏßÄ Ï†ÑÏ≤¥Ï†ÅÏù∏ ÏÉÅÌô©ÏùÑ ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî."
        } else {
            "Describe where this scene is and what's happening, providing overall context."
        }
        analyzeImage(bitmap, prompt, MODE_SCENE_UNDERSTANDING, useKorean)
    }
    
    /**
     * Create system prompt based on mode and language
     */
    private fun createSystemPrompt(mode: String, useKorean: Boolean): String {
        val basePrompt = when (mode) {
            MODE_OBJECT_DETECTION -> {
                if (useKorean) {
                    "ÎãπÏã†ÏùÄ Î¨ºÏ≤¥ Ïù∏Ïãù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Ïù¥ÎØ∏ÏßÄÏóêÏÑú Î≥¥Ïù¥Îäî Î™®Îì† Î¨ºÏ≤¥Î•º Ï†ïÌôïÌûà ÏãùÎ≥ÑÌïòÍ≥† ÏÑ§Î™ÖÌï©ÎãàÎã§."
                } else {
                    "You are an object detection expert. Identify and describe all objects visible in images accurately."
                }
            }
            MODE_COLOR_ANALYSIS -> {
                if (useKorean) {
                    """ÎãπÏã†ÏùÄ Ï†ïÌôïÌïú ÏÉâÏÉÅ Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Îß§Ïö∞ Ïã†Ï§ëÌïòÍ≤å ÏÉâÏÉÅÏùÑ Í¥ÄÏ∞∞ÌïòÏÑ∏Ïöî.
                    Ï§ëÏöî: ÎÖ∏ÎûÄÏÉâÍ≥º ÌååÎûÄÏÉâÏùÑ Ï†àÎåÄ ÌòºÎèôÌïòÏßÄ ÎßàÏÑ∏Ïöî. 
                    - ÎÖ∏ÎûÄÏÉâ(Yellow): Î∞ùÍ≥† Îî∞ÎúªÌïú ÏÉâ, ÌÉúÏñë ÏÉâÍπî
                    - ÌååÎûÄÏÉâ(Blue): Ï∞®Í∞ëÍ≥† ÏãúÏõêÌïú ÏÉâ, ÌïòÎäò/Î∞îÎã§ ÏÉâÍπî
                    ÏÉâÏÉÅÏùÑ ÎßêÌïòÍ∏∞ Ï†ÑÏóê Îëê Î≤à ÌôïÏù∏ÌïòÏÑ∏Ïöî. Ï†ïÌôïÌïú ÏÉâÏÉÅÎ™ÖÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî."""
                } else {
                    """You are a precise color analysis expert. Observe colors very carefully.
                    CRITICAL: Never confuse yellow with blue or vice versa.
                    - Yellow: Bright, warm color like the sun
                    - Blue: Cool, cold color like sky/ocean
                    Double-check before stating any color. Use accurate color names."""
                }
            }
            MODE_TEXT_READING -> {
                if (useKorean) {
                    "ÎãπÏã†ÏùÄ OCR Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÌÖçÏä§Ìä∏Î•º Ï†ïÌôïÌûà ÏùΩÍ≥† Ï†ÑÏÇ¨Ìï©ÎãàÎã§."
                } else {
                    "You are an OCR expert. Read and transcribe text from images accurately."
                }
            }
            MODE_SCENE_UNDERSTANDING -> {
                if (useKorean) {
                    "ÎãπÏã†ÏùÄ Ïû•Î©¥ Ïù¥Ìï¥ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Ïù¥ÎØ∏ÏßÄÏùò Ï†ÑÏ≤¥Ï†ÅÏù∏ Îß•ÎùΩÍ≥º ÏÉÅÌô©ÏùÑ ÌååÏïÖÌï©ÎãàÎã§."
                } else {
                    "You are a scene understanding expert. Comprehend the overall context and situation in images."
                }
            }
            else -> { // MODE_GENERAL
                if (useKorean) {
                    """ÎãπÏã†ÏùÄ AR ÏïàÍ≤ΩÏùÑ ÏúÑÌïú Ï†ïÎ∞Ä ÎπÑÏ†Ñ Î∂ÑÏÑù AIÏûÖÎãàÎã§. ÏÇ¨Ïö©ÏûêÍ∞Ä Î≥¥Í≥† ÏûàÎäî Í≤ÉÏùÑ Ï†ïÌôïÌûà ÏÑ§Î™ÖÌï©ÎãàÎã§.
                    ÌäπÌûà ÏÉâÏÉÅ Ïù∏ÏãùÏóê Îß§Ïö∞ Ïã†Ï§ëÌï¥Ïïº Ìï©ÎãàÎã§:
                    - ÎÖ∏ÎûÄÏÉâÏùÄ Î∞ùÍ≥† Îî∞ÎúªÌïú ÏÉâ (ÌÉúÏñë, Î∞îÎÇòÎÇò ÏÉâ)
                    - ÌååÎûÄÏÉâÏùÄ Ï∞®Í∞ëÍ≥† ÏãúÏõêÌïú ÏÉâ (ÌïòÎäò, Î∞îÎã§ ÏÉâ)
                    - Ï†àÎåÄ ÎÖ∏ÎûÄÏÉâÏùÑ ÌååÎûÄÏÉâÏúºÎ°ú, ÌååÎûÄÏÉâÏùÑ ÎÖ∏ÎûÄÏÉâÏúºÎ°ú Ï∞©Í∞ÅÌïòÏßÄ ÎßàÏÑ∏Ïöî."""
                } else {
                    """You are a precision vision analysis AI for AR glasses. Describe what the user is looking at accurately.
                    Be extremely careful with color recognition:
                    - Yellow is bright and warm (sun, banana color)
                    - Blue is cool and cold (sky, ocean color) 
                    - Never confuse yellow with blue or vice versa."""
                }
            }
        }
        
        return if (useKorean) {
            "$basePrompt Ï§ëÏöî: Î™®Îì† ÏùëÎãµÏùÄ Î∞òÎìúÏãú ÌïúÍµ≠Ïñ¥Î°úÎßå Ìï¥Ï£ºÏÑ∏Ïöî. ÏòÅÏñ¥Îäî Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÎßàÏÑ∏Ïöî. Only respond in Korean language."
        } else {
            "$basePrompt Respond in English."
        }
    }
    
    /**
     * Create default user prompt based on mode
     */
    private fun createDefaultPrompt(mode: String, useKorean: Boolean): String {
        return when (mode) {
            MODE_OBJECT_DETECTION -> {
                if (useKorean) "Ïù¥ Ïù¥ÎØ∏ÏßÄÏóê Î¨¥ÏóáÏù¥ ÏûàÎÇòÏöî?" else "What objects are in this image?"
            }
            MODE_COLOR_ANALYSIS -> {
                if (useKorean) "Ïù¥ Ïù¥ÎØ∏ÏßÄÏùò ÏÉâÏÉÅÏùÑ ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî." else "Describe the colors in this image."
            }
            MODE_TEXT_READING -> {
                if (useKorean) "Ïù¥ Ïù¥ÎØ∏ÏßÄÏùò ÌÖçÏä§Ìä∏Î•º ÏùΩÏñ¥Ï£ºÏÑ∏Ïöî." else "Read the text in this image."
            }
            MODE_SCENE_UNDERSTANDING -> {
                if (useKorean) "Ïù¥ Ïû•Î©¥ÏùÑ ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî." else "Describe this scene."
            }
            else -> {
                if (useKorean) "Ïù¥ Ïù¥ÎØ∏ÏßÄÎ•º ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî." else "Describe this image."
            }
        }
    }
    
    /**
     * Build the vision API request JSON
     */
    private fun buildVisionRequest(
        base64Image: String,
        systemPrompt: String,
        userPrompt: String
    ): String {
        val request = JSONObject().apply {
            put("model", VISION_MODEL)
            put("messages", JSONArray().apply {
                // System message
                put(JSONObject().apply {
                    put("role", "system")
                    put("content", systemPrompt)
                })
                
                // User message with image
                put(JSONObject().apply {
                    put("role", "user")
                    put("content", JSONArray().apply {
                        // Text part
                        put(JSONObject().apply {
                            put("type", "text")
                            put("text", userPrompt)
                        })
                        
                        // Image part
                        put(JSONObject().apply {
                            put("type", "image_url")
                            put("image_url", JSONObject().apply {
                                put("url", "data:image/jpeg;base64,$base64Image")
                                put("detail", "low") // Context7: Use low detail for faster processing
                            })
                        })
                    })
                })
            })
            
            // Context7: Ultra-speed parameters for real-time AR interaction
            put("max_tokens", 150)      // Shorter responses for speed
            put("temperature", 0.0)     // Deterministic for fastest response
            put("top_p", 0.9)          // Focus on most likely tokens
            put("frequency_penalty", 0.2) // Reduce repetition
        }
        
        return request.toString()
    }
    
    /**
     * Convert bitmap to base64 string
     */
    private fun bitmapToBase64(bitmap: Bitmap): String {
        // Resize if needed
        val resizedBitmap = if (bitmap.width > MAX_IMAGE_SIZE || bitmap.height > MAX_IMAGE_SIZE) {
            val scale = MAX_IMAGE_SIZE.toFloat() / maxOf(bitmap.width, bitmap.height)
            val newWidth = (bitmap.width * scale).toInt()
            val newHeight = (bitmap.height * scale).toInt()
            Bitmap.createScaledBitmap(bitmap, newWidth, newHeight, true)
        } else {
            bitmap
        }
        
        // Convert to JPEG and base64
        val outputStream = ByteArrayOutputStream()
        resizedBitmap.compress(Bitmap.CompressFormat.JPEG, JPEG_QUALITY, outputStream)
        val imageBytes = outputStream.toByteArray()
        
        return Base64.encodeToString(imageBytes, Base64.NO_WRAP)
    }
    
    /**
     * Clear the analysis cache
     */
    fun clearCache() {
        analysisCache.clear()
        Log.d(TAG, "Analysis cache cleared")
    }
    
    /**
     * Clean up resources
     */
    /**
     * üöÄ ULTRA-FAST: Build optimized API request for maximum speed
     */
    private fun buildUltraFastVisionRequest(
        base64Image: String,
        systemPrompt: String,
        userPrompt: String
    ): String {
        val request = JSONObject().apply {
            put("model", VISION_MODEL)
            put("messages", JSONArray().apply {
                // User message with image only (skip system message to save tokens)
                put(JSONObject().apply {
                    put("role", "user")
                    put("content", JSONArray().apply {
                        // Text part - ultra-concise
                        put(JSONObject().apply {
                            put("type", "text")
                            put("text", "$userPrompt (Í∞ÑÍ≤∞ÌïòÍ≤å)") // Concise but not extreme
                        })
                        
                        // Image part
                        put(JSONObject().apply {
                            put("type", "image_url")
                            put("image_url", JSONObject().apply {
                                put("url", "data:image/jpeg;base64,$base64Image")
                                put("detail", "low") // Fastest processing
                            })
                        })
                    })
                })
            })
            
            // üöÄ EXTREME optimization for sub-second response
            put("max_tokens", ULTRA_FAST_MAX_TOKENS)  // 100 tokens for good quality
            put("temperature", 0.0)     // No randomness
            put("top_p", 0.1)          // Ultra-focused
            put("presence_penalty", 0.0)
            put("frequency_penalty", 0.0)
        }
        
        return request.toString()
    }
    
    /**
     * üöÄ Create ultra-fast system prompts (minimal tokens)
     */
    private fun createUltraFastSystemPrompt(mode: String, useKorean: Boolean): String {
        return if (useKorean) {
            "Ìïú Ï§ÑÎ°ú ÎãµÌïòÏÑ∏Ïöî."
        } else {
            "Answer in one line."
        }
    }
    
    /**
     * üöÄ Create ultra-fast prompts (minimal tokens)
     */
    private fun createUltraFastPrompt(mode: String, useKorean: Boolean): String {
        return when (mode) {
            MODE_OBJECT_DETECTION -> {
                if (useKorean) "Î¨¥Ïóá?" else "What?"
            }
            MODE_COLOR_ANALYSIS -> {
                if (useKorean) "ÏÉâÍπî?" else "Color?"
            }
            MODE_TEXT_READING -> {
                if (useKorean) "Í∏ÄÏûê?" else "Text?"
            }
            MODE_SCENE_UNDERSTANDING -> {
                if (useKorean) "Ïñ¥Îîî?" else "Where?"
            }
            else -> {
                if (useKorean) "Î≥¥Ïù¥Îäî Í≤É?" else "What's visible?"
            }
        }
    }
    
    fun destroy() {
        coroutineScope.cancel()
        client.dispatcher.executorService.shutdown()
        clearCache()
        Log.d(TAG, "VisionAnalyzer destroyed")
    }
}