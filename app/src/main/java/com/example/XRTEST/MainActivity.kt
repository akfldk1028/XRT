package com.example.XRTEST

import android.Manifest
import android.annotation.SuppressLint
import android.os.Bundle
import androidx.activity.ComponentActivity
import androidx.activity.compose.rememberLauncherForActivityResult
import androidx.activity.compose.setContent
import androidx.activity.enableEdgeToEdge
import androidx.activity.result.contract.ActivityResultContracts
import androidx.compose.foundation.layout.Box
import androidx.compose.foundation.layout.Arrangement
import androidx.compose.foundation.layout.Row
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.foundation.layout.padding
import androidx.compose.foundation.layout.size
import androidx.compose.foundation.layout.height
import androidx.compose.foundation.layout.heightIn
import androidx.compose.foundation.shape.CornerSize
import androidx.compose.animation.AnimatedVisibility
import androidx.compose.animation.fadeIn
import androidx.compose.animation.fadeOut
import androidx.compose.foundation.shape.RoundedCornerShape
import androidx.compose.material3.FilledTonalIconButton
import androidx.compose.material3.Icon
import androidx.compose.material3.IconButton
import androidx.compose.material3.Surface
import androidx.compose.material3.Text
import androidx.compose.runtime.Composable
import androidx.compose.foundation.background
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.res.painterResource
import androidx.compose.ui.res.stringResource
import androidx.compose.ui.tooling.preview.Preview
import androidx.compose.ui.tooling.preview.PreviewLightDark
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import androidx.compose.runtime.*
import androidx.compose.runtime.rememberCoroutineScope
import androidx.compose.ui.platform.LocalContext
import kotlinx.coroutines.launch
import androidx.lifecycle.viewmodel.compose.viewModel
import androidx.xr.compose.platform.LocalHasXrSpatialFeature
import androidx.xr.compose.platform.LocalSpatialCapabilities
import androidx.xr.compose.platform.LocalSpatialConfiguration
import androidx.xr.compose.spatial.EdgeOffset
import androidx.xr.compose.spatial.Orbiter
import androidx.xr.compose.spatial.OrbiterEdge
import androidx.xr.compose.spatial.Subspace
import androidx.xr.compose.subspace.SpatialPanel
import androidx.xr.compose.subspace.layout.SpatialRoundedCornerShape
import androidx.xr.compose.subspace.layout.SubspaceModifier
import androidx.xr.compose.subspace.layout.height
import androidx.xr.compose.subspace.layout.movable
import androidx.xr.compose.subspace.layout.resizable
import androidx.xr.compose.subspace.layout.width
import com.example.XRTEST.ui.theme.XRTESTTheme
import com.example.XRTEST.ui.CrosshairOverlay
import com.example.XRTEST.ui.TextInputField
import com.example.XRTEST.ui.Camera2Preview
import com.example.XRTEST.ui.VoiceSettingsDialog
import com.example.XRTEST.ui.VoiceSettingsButton
import com.example.XRTEST.camera.Camera2Manager
import com.example.XRTEST.camera.CameraDiagnostics
import com.example.XRTEST.camera.CameraDebugHelper
import com.example.XRTEST.voice.VoiceManager
import com.example.XRTEST.network.A2AClient
import com.example.XRTEST.vision.VisionIntegration
import com.example.XRTEST.vision.VoiceSettingsManager
import com.example.XRTEST.vision.TtsConfiguration
import android.media.AudioManager
import android.media.AudioDeviceInfo
import android.content.Context
import android.util.Log
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.Row
import androidx.compose.foundation.layout.fillMaxWidth
import androidx.compose.material3.TextButton
import androidx.compose.material3.Button
import androidx.compose.material3.ButtonDefaults
import androidx.compose.material3.FloatingActionButton
import androidx.compose.material3.FloatingActionButtonDefaults
import androidx.compose.runtime.LaunchedEffect
import androidx.compose.runtime.DisposableEffect
import androidx.compose.runtime.collectAsState
import com.example.XRTEST.R
import kotlinx.coroutines.delay

// ğŸš€ ì•±ì˜ ì‹œì‘ì : Android XR ì•±ì˜ ë©”ì¸ ì•¡í‹°ë¹„í‹°
// ì´ í´ë˜ìŠ¤ê°€ ì•±ì´ ì‹¤í–‰ë  ë•Œ ê°€ì¥ ë¨¼ì € ì‹œì‘ë˜ëŠ” ê³³ì…ë‹ˆë‹¤
class MainActivity : ComponentActivity() {

    @SuppressLint("RestrictedApi")
    // â­ onCreate: ì•±ì´ ì‹œì‘ë  ë•Œ ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ëŠ” ë©”ì„œë“œ
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        // í™”ë©´ ê°€ì¥ìë¦¬ê¹Œì§€ UI í™•ì¥ (ìƒíƒœë°”, ë„¤ë¹„ê²Œì´ì…˜ë°” ì˜ì—­ê¹Œì§€ ì‚¬ìš©)
        enableEdgeToEdge()

        // Jetpack Compose UI ì„¤ì • ì‹œì‘
        setContent {
            // ì•±ì˜ í…Œë§ˆ ì ìš©
            XRTESTTheme {
                // XR ê³µê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                val spatialConfiguration = LocalSpatialConfiguration.current
                
                // ğŸ”€ XR ê¸°ëŠ¥ ì§€ì› ì—¬ë¶€ì— ë”°ë¥¸ UI ë¶„ê¸°
                if (LocalSpatialCapabilities.current.isSpatialUiEnabled) {
                    // âœ¨ XR/ê³µê°„ UI ëª¨ë“œ (3D í™˜ê²½)
                    Subspace {
                        MySpatialContent(
                            // í™ˆ ìŠ¤í˜ì´ìŠ¤ ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ì½œë°± í•¨ìˆ˜ ì „ë‹¬
                            onRequestHomeSpaceMode = { spatialConfiguration.requestHomeSpaceMode() }
                        )
                    }
                } else {
                    // ğŸ“± ì¼ë°˜ 2D UI ëª¨ë“œ (í‰ë©´ í™”ë©´)
                    My2DContent(
                        // í’€ ìŠ¤í˜ì´ìŠ¤ ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ì½œë°± í•¨ìˆ˜ ì „ë‹¬
                        onRequestFullSpaceMode = { spatialConfiguration.requestFullSpaceMode() }
                    )
                }
            }
        }
    }
}

// ğŸŒŒ XR ê³µê°„ UI ì½˜í…ì¸  (3D í™˜ê²½ì—ì„œ í‘œì‹œ)
// VR/AR í—¤ë“œì…‹ì´ë‚˜ XR ì§€ì› ê¸°ê¸°ì—ì„œ ì‹¤í–‰ë˜ëŠ” 3D ê³µê°„ UI
@SuppressLint("RestrictedApi")
@Composable
fun MySpatialContent(onRequestHomeSpaceMode: () -> Unit) {
    // 3D ê³µê°„ì— ë– ìˆëŠ” íŒ¨ë„ ìƒì„±
    // - í¬ê¸°: 1280x800dp
    // - ì‚¬ìš©ìê°€ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥ (resizable)
    // - ì‚¬ìš©ìê°€ ìœ„ì¹˜ ì´ë™ ê°€ëŠ¥ (movable)
    SpatialPanel(
        SubspaceModifier
            .width(1280.dp)
            .height(800.dp)
            .resizable()
            .movable()
    ) {
        Surface {
            MainContent(
                modifier = Modifier.fillMaxSize()
            )
        }
        // íŒ¨ë„ ì£¼ë³€ì— ë– ìˆëŠ” ê¶¤ë„ ë²„íŠ¼ (Orbiter)
        // - ìœ„ì¹˜: íŒ¨ë„ ìƒë‹¨
        // - ì•ˆìª½ìœ¼ë¡œ 20dp ì˜¤í”„ì…‹
        // - ì˜¤ë¥¸ìª½ ì •ë ¬
        // - ë‘¥ê·¼ ëª¨ì„œë¦¬ (28dp)
        Orbiter(
            position = OrbiterEdge.Top,
            offset = EdgeOffset.inner(offset = 20.dp),
            alignment = Alignment.End,
            shape = SpatialRoundedCornerShape(CornerSize(28.dp))
        ) {
            HomeSpaceModeIconButton(
                onClick = onRequestHomeSpaceMode,
                modifier = Modifier.size(56.dp)
            )
        }
    }
}

// ğŸ“± 2D í‰ë©´ UI ì½˜í…ì¸  (ì¼ë°˜ í™”ë©´ì—ì„œ í‘œì‹œ)
// XR ê¸°ëŠ¥ì´ ì—†ëŠ” ì¼ë°˜ ê¸°ê¸°ë‚˜ 2D ëª¨ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” UI
@SuppressLint("RestrictedApi")
@Composable
fun My2DContent(onRequestFullSpaceMode: () -> Unit) {
    Surface {
        Row(
            modifier = Modifier.fillMaxSize(),
            horizontalArrangement = Arrangement.SpaceBetween
        ) {
            MainContent(modifier = Modifier.fillMaxSize())
            // XR ê¸°ëŠ¥ì´ ì§€ì›ë˜ëŠ” ê¸°ê¸°ì¸ ê²½ìš°ì—ë§Œ ëª¨ë“œ ì „í™˜ ë²„íŠ¼ í‘œì‹œ
            if (LocalHasXrSpatialFeature.current) {
                // í’€ ìŠ¤í˜ì´ìŠ¤ ëª¨ë“œ(3D)ë¡œ ì „í™˜í•˜ëŠ” ë²„íŠ¼
                FullSpaceModeIconButton(
                    onClick = onRequestFullSpaceMode,
                    modifier = Modifier.padding(32.dp)
                )
            }
        }
    }
}

// ğŸ“ AR Glass Q&A ì‹œìŠ¤í…œ ë©”ì¸ ì½˜í…ì¸  with OpenAI Realtime API
@Composable
fun MainContent(modifier: Modifier = Modifier) {
    val context = LocalContext.current
    val coroutineScope = rememberCoroutineScope()
    
    // OpenAI API Key - BuildConfigì—ì„œ ì½ì–´ì˜¤ê¸°
    val openaiApiKey = com.example.XRTEST.BuildConfig.OPENAI_API_KEY
    
    // API í‚¤ ê²€ì¦
    var apiKeyError by remember { mutableStateOf<String?>(null) }
    
    LaunchedEffect(Unit) {
        if (openaiApiKey.isBlank() || openaiApiKey == "your-actual-openai-api-key-here") {
            apiKeyError = """
                âš ï¸ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!
                
                ì„¤ì • ë°©ë²•:
                1. https://platform.openai.com/api-keys ì—ì„œ API í‚¤ ìƒì„±
                2. gradle.properties íŒŒì¼ì—ì„œ OPENAI_API_KEY=sk-... ì„¤ì •
                3. ì•± ì¬ë¹Œë“œ
                
                í˜„ì¬ ìƒíƒœ: API í‚¤ ì—†ìŒ - Realtime API ì‚¬ìš© ë¶ˆê°€
            """.trimIndent()
        }
    }
    
    // AR Glass Q&A ì‹œìŠ¤í…œ ë§¤ë‹ˆì €ë“¤
    val cameraManager = remember { Camera2Manager(context) }
    val voiceManager = remember { VoiceManager(context, openaiApiKey) }  // Pass API key for OpenAI TTS
    val a2aClient = remember { A2AClient() }
    
    // ì¹´ë©”ë¼ ì§„ë‹¨ ë„êµ¬
    val cameraDiagnostics = remember { CameraDiagnostics(context) }
    val cameraDebugHelper = remember { CameraDebugHelper(context) }
    
    // ë§ˆì´í¬ ê°€ìš©ì„± í™•ì¸
    var hasMicrophone by remember { mutableStateOf(true) }
    var useTextInput by remember { mutableStateOf(false) }
    
    LaunchedEffect(Unit) {
        // AudioManagerë¥¼ í†µí•´ ë§ˆì´í¬ ë””ë°”ì´ìŠ¤ í™•ì¸
        val audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
        val audioDevices = audioManager.getDevices(AudioManager.GET_DEVICES_INPUTS)
        hasMicrophone = audioDevices.any { device ->
            device.type == AudioDeviceInfo.TYPE_BUILTIN_MIC ||
            device.type == AudioDeviceInfo.TYPE_WIRED_HEADSET ||
            device.type == AudioDeviceInfo.TYPE_USB_HEADSET ||
            device.type == AudioDeviceInfo.TYPE_BLUETOOTH_SCO
        }
        
        // ë§ˆì´í¬ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì…ë ¥ ëª¨ë“œ í™œì„±í™”
        useTextInput = !hasMicrophone
        
        if (!hasMicrophone) {
            // Log.d("MainActivity", "No microphone detected - enabling text input mode") // Reduced logging
        }
    }
    
    // Voice Settings Manager
    val voiceSettingsManager = remember { VoiceSettingsManager(context) }
    
    // TTS Configuration Manager
    val ttsConfiguration = remember { TtsConfiguration(context) }
    
    // OpenAI Realtime API í†µí•©
    val visionIntegration = remember {
        VisionIntegration(
            context = context,
            apiKey = openaiApiKey,
            camera2Manager = cameraManager,
            voiceManager = voiceManager
        )
    }
    
    // Apply saved voice settings to VisionIntegration
    LaunchedEffect(visionIntegration) {
        val savedVoice = voiceSettingsManager.getSavedVoice()
        val useKorean = voiceSettingsManager.isKoreanMode()
        visionIntegration.setVoice(savedVoice)
        visionIntegration.setLanguageMode(useKorean)
        
        // Apply TTS configuration
        val useAndroidForKorean = ttsConfiguration.useAndroidForKorean.value
        val forceAndroid = ttsConfiguration.forceAndroidTts.value
        visionIntegration.configureTts(useAndroidForKorean, forceAndroid)
        
        // Set VoiceManager language and speech rate
        voiceManager.setLanguage(useKorean)
        voiceManager.setSpeechRate(ttsConfiguration.speechRate.value)
    }
    
    // ì‹œìŠ¤í…œ ìƒíƒœ
    var isSystemReady by remember { mutableStateOf(false) }
    var currentResponse by remember { mutableStateOf<String?>(null) }
    val integrationState by visionIntegration.state.collectAsState()
    val lastResponse by visionIntegration.lastResponse.collectAsState()
    val isProcessing by visionIntegration.isProcessing.collectAsState()
    
    // ì¹´ë©”ë¼ ë””ë²„ê·¸ ì •ë³´
    var cameraDebugInfo by remember { mutableStateOf("") }
    var showCameraDebug by remember { mutableStateOf(false) } // ë””ë²„ê·¸ ì •ë³´ ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€
    
    // Voice Settings Dialog state
    var showVoiceSettings by remember { mutableStateOf(false) }
    
    // ê¶Œí•œ ìš”ì²­
    val permissionLauncher = rememberLauncherForActivityResult(
        ActivityResultContracts.RequestMultiplePermissions()
    ) { permissions ->
        val cameraGranted = permissions[Manifest.permission.CAMERA] == true
        val audioGranted = permissions[Manifest.permission.RECORD_AUDIO] == true
        
        if (cameraGranted && audioGranted) {
            // ì¹´ë©”ë¼ ì§„ë‹¨ ì‹¤í–‰ (ì¡°ìš©íˆ)
            // Log.d("MainActivity", "Running camera diagnostics...") // Reduced logging
            cameraDiagnostics.logDiagnostics()
            val quickCheck = cameraDiagnostics.quickWebcamCheck()
            // Log.d("MainActivity", quickCheck) // Reduced logging
            
            // ì¶”ê°€ ë””ë²„ê·¸ ì§„ë‹¨ - DISABLED to reduce spam
            // val fullDiagnostics = cameraDebugHelper.runFullDiagnostics()
            // Log.d("MainActivity", fullDiagnostics)
            
            // ê°•ì œ ì¹´ë©”ë¼ ID "0" í…ŒìŠ¤íŠ¸ - DISABLED to reduce spam
            // val forceTest = cameraDebugHelper.testForceCameraZero()
            // Log.d("MainActivity", "Force Camera 0 Test: $forceTest")
            
            // ê¶Œí•œì´ ìŠ¹ì¸ë˜ë©´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            cameraManager.initialize()
            
            // ì¹´ë©”ë¼ ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘ (ìµœì†Œí™”)
            cameraDebugInfo = cameraManager.debugCameraInfo()
            // Log only if there's an actual problem
            if (cameraDebugInfo.contains("NO CAMERAS")) {
                Log.e("MainActivity", "Camera not detected: $cameraDebugInfo")
            }
            
            // ì¹´ë©”ë¼ê°€ ì—†ìœ¼ë©´ ì—ë®¬ë ˆì´í„° ì„¤ì • ì•ˆë‚´
            if (cameraDebugInfo.contains("NO CAMERAS DETECTED")) {
                Log.e("MainActivity", "âš ï¸ No webcam configured - see screen for instructions")
                showCameraDebug = true // í™”ë©´ì— ë””ë²„ê·¸ ì •ë³´ ê°•ì œ í‘œì‹œ
            } else {
                // ì¹´ë©”ë¼ê°€ ê°ì§€ë˜ë©´ ì‹œì‘
                voiceManager.initialize()
                cameraManager.startCamera()
                
                // ì¹´ë©”ë¼ ìƒíƒœ í™•ì¸ (ì¡°ìš©íˆ)
                val cameraStatus = cameraManager.getCameraStatus()
                // Log.d("MainActivity", "Camera Status: $cameraStatus") // Reduced logging
            
                // OpenAI Realtime API ì´ˆê¸°í™”
                visionIntegration.initialize()
                isSystemReady = true
            }
        }
    }
    
    // ì•± ì‹œì‘ ì‹œ ê¶Œí•œ ìš”ì²­
    LaunchedEffect(Unit) {
        permissionLauncher.launch(
            arrayOf(
                Manifest.permission.CAMERA,
                Manifest.permission.RECORD_AUDIO
            )
        )
    }
    
    // OpenAI Realtime API ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ
    LaunchedEffect(integrationState) {
        if (integrationState == VisionIntegration.IntegrationState.READY && isSystemReady) {
            visionIntegration.startSession()
        }
    }
    
    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    DisposableEffect(Unit) {
        onDispose {
            visionIntegration.release()
        }
    }
    
    // Response fade out timer
    var showResponse by remember { mutableStateOf(false) }
    var responseTimer by remember { mutableStateOf(0L) }
    
    LaunchedEffect(lastResponse) {
        lastResponse?.let {
            showResponse = true
            responseTimer = System.currentTimeMillis()
            delay(5000)  // Show for 5 seconds
            if (System.currentTimeMillis() - responseTimer >= 5000) {
                showResponse = false
            }
        }
    }
    
    // AR Glass Q&A UI with Realtime API - TRUE FULL SCREEN
    Box(modifier = modifier.fillMaxSize()) {
        // ì¹´ë©”ë¼ í”„ë¦¬ë·° - ì „ì²´ í™”ë©´ ì±„ìš°ê¸° (ì§„ì§œ FULL SCREEN, íŒ¨ë”© ì—†ìŒ)
        if (isSystemReady && !cameraDebugInfo.contains("NO CAMERAS DETECTED")) {
            // Camera2Managerì™€ ì—°ë™ëœ ì¹´ë©”ë¼ í”„ë¦¬ë·° - FULL SCREEN
            Camera2Preview(
                modifier = Modifier.fillMaxSize(),  // Fill entire screen edge-to-edge
                onSurfaceReady = { surface ->
                    // Camera2Managerì— í”„ë¦¬ë·° Surface ì „ë‹¬
                    cameraManager.setPreviewSurface(surface)
                }
            )
        }
        
        // API í‚¤ ì˜¤ë¥˜ í‘œì‹œ
        if (apiKeyError != null) {
            Text(
                text = apiKeyError!!,
                modifier = Modifier
                    .align(Alignment.Center)
                    .padding(16.dp)
            )
        } else if (isSystemReady || showCameraDebug) {
            // ì¹´ë©”ë¼ ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ì—ë®¬ë ˆì´í„° ì„¤ì • ë¬¸ì œì‹œ)
            if (showCameraDebug && cameraDebugInfo.contains("NO CAMERAS DETECTED")) {
                Column(
                    modifier = Modifier
                        .align(Alignment.Center)
                        .padding(16.dp)
                ) {
                    Text(
                        text = "âŒ ì›¹ìº ì´ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\n\n" +
                               cameraDebugInfo + "\n\n" +
                               "ğŸ‘† ìœ„ ì§€ì¹¨ì„ ë”°ë¼ AVD ì„¤ì •ì„ ìˆ˜ì •í•˜ì„¸ìš”.",
                        modifier = Modifier.padding(8.dp)
                    )
                    
                    TextButton(
                        onClick = { 
                            // ì¹´ë©”ë¼ ì¬ê²€ì‚¬
                            cameraManager.initialize()
                            cameraDebugInfo = cameraManager.debugCameraInfo()
                            if (!cameraDebugInfo.contains("NO CAMERAS DETECTED")) {
                                cameraManager.startCamera()
                                showCameraDebug = false
                                isSystemReady = true
                            }
                        }
                    ) {
                        Text("ğŸ”„ ì›¹ìº  ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„")
                    }
                }
            } else if (isSystemReady) {
                // ì‹­ìê°€ ì˜¤ë²„ë ˆì´ í‘œì‹œ (íƒ€ê²ŸíŒ… ìƒíƒœ ë°˜ì˜)
                CrosshairOverlay(
                    isActive = true,
                    isTargeting = integrationState == VisionIntegration.IntegrationState.PROCESSING ||
                               integrationState == VisionIntegration.IntegrationState.RESPONDING,
                    modifier = Modifier.fillMaxSize()
                )
                
                // AI ì‘ë‹µ í‘œì‹œ - ìƒë‹¨ì— í˜ì´ë“œ ì¸/ì•„ì›ƒ ì• ë‹ˆë©”ì´ì…˜ê³¼ í•¨ê»˜
                AnimatedVisibility(
                    visible = showResponse && lastResponse != null,
                    enter = fadeIn(),
                    exit = fadeOut(),
                    modifier = Modifier
                        .align(Alignment.TopCenter)
                        .padding(top = 80.dp)
                ) {
                    Box(
                        modifier = Modifier
                            .background(
                                Color.Black.copy(alpha = 0.7f),
                                shape = RoundedCornerShape(12.dp)
                            )
                            .padding(horizontal = 20.dp, vertical = 12.dp)
                    ) {
                        Text(
                            text = lastResponse?.text ?: "",
                            color = Color.White,
                            style = androidx.compose.material3.MaterialTheme.typography.bodyLarge,
                            fontSize = 16.sp,
                            modifier = Modifier.fillMaxWidth(0.9f)
                        )
                    }
                }
                
                // ğŸ¤ ë§ˆì´í¬ í”Œë¡œíŒ… ë²„íŠ¼ - í™”ë©´ í•˜ë‹¨ ì¤‘ì•™ì— í˜„ëŒ€ì ì¸ ë””ìì¸
                FloatingActionButton(
                    onClick = {
                        // ìŒì„± ì¸ì‹ í† ê¸€
                        if (voiceManager.isListening.value) {
                            voiceManager.stopListening()
                        } else {
                            voiceManager.startListening()
                        }
                    },
                    modifier = Modifier
                        .align(Alignment.BottomCenter)
                        .padding(bottom = 100.dp)  // ì¶©ë¶„í•œ ê³µê°„ í™•ë³´
                        .size(72.dp),  // ì ë‹¹í•œ í¬ê¸°
                    containerColor = if (voiceManager.isListening.collectAsState().value) {
                        Color(0xFFE91E63)  // Material Pink - ë…¹ìŒ ì¤‘
                    } else {
                        Color(0xFF673AB7)  // Material Deep Purple - ëŒ€ê¸° ì¤‘
                    },
                    elevation = FloatingActionButtonDefaults.elevation(
                        defaultElevation = 12.dp,
                        pressedElevation = 16.dp
                    ),
                    shape = RoundedCornerShape(50)  // ì™„ì „íˆ ë‘¥ê·¼ ëª¨ì–‘
                ) {
                    Icon(
                        painter = painterResource(
                            id = if (voiceManager.isListening.collectAsState().value) {
                                android.R.drawable.ic_btn_speak_now
                            } else {
                                android.R.drawable.ic_btn_speak_now
                            }
                        ),
                        contentDescription = "Voice Recording",
                        tint = Color.White,
                        modifier = Modifier.size(32.dp)  // ì ë‹¹í•œ ì•„ì´ì½˜ í¬ê¸°
                    )
                }
                
                // ìƒíƒœ í‘œì‹œ - ìƒë‹¨ ì™¼ìª½ ì½”ë„ˆì— ìµœì†Œí™”
                Box(
                    modifier = Modifier
                        .align(Alignment.TopStart)
                        .padding(16.dp)
                ) {
                    val statusIcon = when (integrationState) {
                        VisionIntegration.IntegrationState.CONNECTING -> "ğŸ”Œ"
                        VisionIntegration.IntegrationState.LISTENING -> "ğŸ¤"
                        VisionIntegration.IntegrationState.PROCESSING -> "â³"
                        VisionIntegration.IntegrationState.RESPONDING -> "ğŸ’¬"
                        VisionIntegration.IntegrationState.ERROR -> "âŒ"
                        else -> "ğŸ¯"
                    }
                    
                    Box(
                        modifier = Modifier
                            .background(
                                Color.Black.copy(alpha = 0.4f),
                                shape = RoundedCornerShape(20.dp)
                            )
                            .padding(horizontal = 12.dp, vertical = 6.dp)
                    ) {
                        Text(
                            text = statusIcon,
                            fontSize = 20.sp
                        )
                    }
                }
                
                // ìµœì†Œí™”ëœ ì»¨íŠ¸ë¡¤ - í•˜ë‹¨ ìš°ì¸¡ ì½”ë„ˆì— ì‘ê²Œ
                Row(
                    modifier = Modifier
                        .align(Alignment.BottomEnd)
                        .padding(16.dp),
                    horizontalArrangement = Arrangement.spacedBy(8.dp)
            ) {
                
                    // ğŸ“¸ ìº¡ì²˜ ë²„íŠ¼ - ì‘ì€ í”Œë¡œíŒ… ë²„íŠ¼
                    FloatingActionButton(
                        onClick = {
                            coroutineScope.launch {
                                if (integrationState != VisionIntegration.IntegrationState.READY && 
                                    integrationState != VisionIntegration.IntegrationState.LISTENING) {
                                    visionIntegration.startSession()
                                    delay(1000)
                                }
                                
                                val jpegData = cameraManager.captureCurrentFrameAsJpeg()
                                if (jpegData != null) {
                                    visionIntegration.sendQuery("What do you see in this image?")
                                } else {
                                    Log.e("MainActivity", "âŒ Failed to capture image")
                                }
                            }
                        },
                        modifier = Modifier.size(48.dp),
                        containerColor = Color(0xFF4CAF50).copy(alpha = 0.9f),
                        elevation = FloatingActionButtonDefaults.elevation(4.dp)
                    ) {
                        Icon(
                            painter = painterResource(id = android.R.drawable.ic_menu_camera),
                            contentDescription = "Capture",
                            tint = Color.White,
                            modifier = Modifier.size(24.dp)
                        )
                    }
                    
                    // ğŸ¤/âŒ¨ï¸ ì…ë ¥ ëª¨ë“œ ì „í™˜ - ì‘ì€ í”Œë¡œíŒ… ë²„íŠ¼
                    if (hasMicrophone) {
                        FloatingActionButton(
                            onClick = { useTextInput = !useTextInput },
                            modifier = Modifier.size(48.dp),
                            containerColor = Color(0xFF2196F3).copy(alpha = 0.9f),
                            elevation = FloatingActionButtonDefaults.elevation(4.dp)
                        ) {
                            Icon(
                                painter = painterResource(
                                    id = if (useTextInput) android.R.drawable.ic_btn_speak_now 
                                         else android.R.drawable.ic_menu_edit
                                ),
                                contentDescription = "Input Mode",
                                tint = Color.White,
                                modifier = Modifier.size(24.dp)
                            )
                        }
                    }
                    
                    // ğŸ™ï¸ ìŒì„± ì„¤ì • ë²„íŠ¼ - Voice Settings
                    FloatingActionButton(
                        onClick = { showVoiceSettings = true },
                        modifier = Modifier.size(48.dp),
                        containerColor = Color(0xFF9C27B0).copy(alpha = 0.9f), // Purple for settings
                        elevation = FloatingActionButtonDefaults.elevation(4.dp)
                    ) {
                        Text(
                            text = "ğŸ™ï¸",
                            fontSize = 20.sp
                        )
                    }
                    
                    androidx.compose.foundation.layout.Spacer(modifier = Modifier.height(12.dp))
                    
                    // ğŸ”Š TTS í…ŒìŠ¤íŠ¸ ë²„íŠ¼
                    FloatingActionButton(
                        onClick = { 
                            // Simple TTS test
                            voiceManager.speak("í…ŒìŠ¤íŠ¸ ìŒì„±ì…ë‹ˆë‹¤. í•œêµ­ì–´ TTSê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
                        },
                        modifier = Modifier.size(48.dp),
                        containerColor = Color(0xFF4CAF50).copy(alpha = 0.9f), // Green for test
                        elevation = FloatingActionButtonDefaults.elevation(4.dp)
                    ) {
                        Text(
                            text = "ğŸ”Š",
                            fontSize = 20.sp
                        )
                    }
                }
                
                // í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ - í•˜ë‹¨ì— í”Œë¡œíŒ…
                if (useTextInput || !hasMicrophone) {
                    Box(
                        modifier = Modifier
                            .align(Alignment.BottomCenter)
                            .fillMaxWidth(0.9f)
                            .padding(bottom = 20.dp)
                            .background(
                                Color.Black.copy(alpha = 0.8f),
                                shape = RoundedCornerShape(24.dp)
                            )
                            .padding(8.dp)
                    ) {
                        TextInputField(
                            enabled = isSystemReady,
                            onSendQuery = { query ->
                                visionIntegration.sendQuery(query)
                            },
                            modifier = Modifier.fillMaxWidth()
                        )
                    }
                }
            }
            
            // ì²˜ë¦¬ ì¤‘ í‘œì‹œ ì œê±° - ìƒíƒœ ì•„ì´ì½˜ìœ¼ë¡œ ì¶©ë¶„í•¨
            
            // ìµœì†Œí™”ëœ ì¹´ë©”ë¼ ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ (ìš°ì¸¡ ìƒë‹¨ ì½”ë„ˆ)
            if (showCameraDebug && cameraDebugInfo.isNotEmpty()) {
                Box(
                    modifier = Modifier
                        .align(Alignment.TopEnd)
                        .padding(8.dp)
                        .background(
                            Color.Black.copy(alpha = 0.5f),
                            shape = androidx.compose.foundation.shape.RoundedCornerShape(4.dp)
                        )
                        .padding(4.dp)
                ) {
                    val simplifiedDebug = when {
                        cameraDebugInfo.contains("NO CAMERAS") -> "ğŸ“· âŒ"
                        cameraDebugInfo.contains("device(s) found") -> {
                            val count = cameraDebugInfo.filter { it.isDigit() }.firstOrNull() ?: '0'
                            "ğŸ“· âœ“ ($count)"
                        }
                        else -> "ğŸ“· ${cameraManager.getCameraStatus()}"
                    }
                    
                    Text(
                        text = simplifiedDebug,
                        color = Color.White.copy(alpha = 0.8f),
                        style = androidx.compose.material3.MaterialTheme.typography.labelSmall,
                        fontSize = 10.sp
                    )
                }
            }
        } else {
            // ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘
            Text(
                text = "ğŸš€ Initializing AR Glass Q&A System with OpenAI GPT-4V...\nGranting camera and microphone permissions required.",
                modifier = Modifier.align(Alignment.Center)
            )
        }
        
        // Voice Settings Dialog
        if (showVoiceSettings) {
            VoiceSettingsDialog(
                onDismiss = { showVoiceSettings = false },
                voiceSettingsManager = voiceSettingsManager,
                visionIntegration = visionIntegration
            )
        }
    }
    
    // ìŒì„± ëª…ë ¹ ì²˜ë¦¬ (OpenAI Realtime API í†µí•©) - ë§ˆì´í¬ê°€ ìˆê³  ìŒì„± ëª¨ë“œì¼ ë•Œë§Œ
    LaunchedEffect(voiceManager.recognizedText.collectAsState().value) {
        val recognizedText = voiceManager.recognizedText.value
        if (recognizedText != null && isSystemReady && 
            integrationState == VisionIntegration.IntegrationState.LISTENING &&
            hasMicrophone && !useTextInput) {
            
            // OpenAI Realtime APIë¡œ ì§ˆë¬¸ ì „ì†¡ (ìŒì„± + ë¹„ì „)
            visionIntegration.sendQuery(recognizedText)
            voiceManager.clearRecognizedText()
        }
    }
    
    // ìŒì„± ì¸ì‹ ì‹œì‘/ì¤‘ì§€ (ë§ˆì´í¬ ëª¨ë“œì— ë”°ë¼)
    LaunchedEffect(useTextInput, hasMicrophone, isSystemReady) {
        if (isSystemReady) {
            if (hasMicrophone && !useTextInput) {
                // ë§ˆì´í¬ê°€ ìˆê³  ìŒì„± ëª¨ë“œë©´ ìŒì„± ì¸ì‹ ì‹œì‘
                voiceManager.startListening()
            } else {
                // í…ìŠ¤íŠ¸ ëª¨ë“œë©´ ìŒì„± ì¸ì‹ ì¤‘ì§€
                voiceManager.stopListening()
            }
        }
    }
    
    // ì‘ë‹µ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
    LaunchedEffect(lastResponse) {
        lastResponse?.let { response ->
            currentResponse = response.text
        }
    }
}

// ğŸ”„ 2D â†’ 3D ì „í™˜ ë²„íŠ¼
// 2D ëª¨ë“œì—ì„œ í’€ ìŠ¤í˜ì´ìŠ¤(3D) ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ë²„íŠ¼
@Composable
fun FullSpaceModeIconButton(onClick: () -> Unit, modifier: Modifier = Modifier) {
    IconButton(onClick = onClick, modifier = modifier) {
        Icon(
            painter = painterResource(id = R.drawable.ic_full_space_mode_switch),
            contentDescription = stringResource(R.string.switch_to_full_space_mode)
        )
    }
}

// ğŸ”„ 3D â†’ 2D ì „í™˜ ë²„íŠ¼  
// 3D ê³µê°„ ëª¨ë“œì—ì„œ í™ˆ ìŠ¤í˜ì´ìŠ¤(2D) ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ë²„íŠ¼
@Composable
fun HomeSpaceModeIconButton(onClick: () -> Unit, modifier: Modifier = Modifier) {
    FilledTonalIconButton(onClick = onClick, modifier = modifier) {
        Icon(
            painter = painterResource(id = R.drawable.ic_home_space_mode_switch),
            contentDescription = stringResource(R.string.switch_to_home_space_mode)
        )
    }
}

@PreviewLightDark
@Composable
fun My2dContentPreview() {
    XRTESTTheme {
        My2DContent(onRequestFullSpaceMode = {})
    }
}

@Preview(showBackground = true)
@Composable
fun FullSpaceModeButtonPreview() {
    XRTESTTheme {
        FullSpaceModeIconButton(onClick = {})
    }
}

@PreviewLightDark
@Composable
fun HomeSpaceModeButtonPreview() {
    XRTESTTheme {
        HomeSpaceModeIconButton(onClick = {})
    }
}