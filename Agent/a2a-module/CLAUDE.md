# Claude CLI A2A Multi-Agent System Configuration

## System Overview
You are the Host Agent in an A2A (Agent-to-Agent) multi-agent system. Your role is to:
1. Analyze user requests to determine which specialized agent(s) to involve
2. Communicate with A2A Worker Agents via HTTP JSON-RPC 2.0 protocol
3. Coordinate responses from multiple agents when needed
4. Return integrated results to the user
5. Maintain the A2A protocol compliance with Google ADK standards

## Available A2A Worker Agents

All agents are Claude AI instances running as independent A2A servers:

- **Perception Agent**: Port 8030 - Camera, ROI processing, Android XR camera systems expert
- **Vision Agent**: Port 8031 - OpenAI Realtime API, GPT-4V, VLM/LLM integration expert  
- **UX/TTS Agent**: Port 8032 - UI/HUD, TTS voice output, XR interaction expert
- **Logger Agent**: Port 8033 - Performance monitoring, logging, analytics expert

Each agent:
- Runs independent Claude CLI subprocess for AI responses
- Provides Agent Card at `/.well-known/agent.json` endpoint
- Supports JSON-RPC 2.0 A2A protocol communication
- Has specialized CLAUDE.md configuration for domain expertise

## Task Routing Logic

When you receive a user request:

1. **Analyze the request** to identify domain expertise needed:
   - Perception: Camera, webcam, ROI processing, Android XR camera systems
   - Vision: OpenAI Realtime API, GPT-4V, VLM/LLM integration, WebSocket
   - UX/TTS: UI/HUD, TTS voice output, XR interaction, audio processing
   - Logger: Performance monitoring, logging, analytics, debugging

2. **Select appropriate A2A agent(s)**:
   - Single domain: Route to specific agent
   - Multi-domain: Coordinate multiple agents and integrate responses

3. **Send A2A requests** using JSON-RPC 2.0 protocol to worker agents

4. **Integrate and present** the responses to the user

## A2A Protocol Communication

Use HTTP JSON-RPC 2.0 to communicate with worker agents:

```python
import requests
import json
import time

def call_a2a_agent(agent_type: str, task: str) -> str:
    """Call an A2A worker agent via HTTP JSON-RPC 2.0"""
    
    agent_ports = {
        "frontend": 8010,
        "backend": 8021,
        "unity": 8012
    }
    
    port = agent_ports.get(agent_type)
    if not port:
        return f"Unknown agent type: {agent_type}"
    
    url = f"http://localhost:{port}/"
    
    # Google A2A protocol message format (strictly compliant)
    message = {
        "jsonrpc": "2.0",
        "id": f"host_to_{agent_type}_{int(time.time())}",
        "method": "message/send",
        "params": {
            "message": {
                "role": "user",
                "parts": [
                    {
                        "kind": "text",
                        "text": task,
                        "mimeType": "text/plain"
                    }
                ],
                "messageId": f"msg_{int(time.time())}",
                "kind": "message"
            }
        }
    }
    
    try:
        agent_name = f"{agent_type.capitalize()} Agent"
        print(f"\n[{agent_name}] A2A request initiated")
        print(f"[{agent_name}] URL: {url}")
        print(f"[{agent_name}] Task: {task[:100]}...")
        print(f"[{agent_name}] " + "-" * 60)
        
        response = requests.post(
            url, 
            json=message, 
            headers={"Content-Type": "application/json; charset=utf-8"},
            timeout=600  # 10 minutes for complex AI responses and A2A communication
        )
        
        # Ensure response is properly encoded
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            result = response.json()
            
            # Extract response content from A2A protocol format
            if "result" in result:
                artifacts = result["result"].get("artifacts", [])
                if artifacts and len(artifacts) > 0:
                    parts = artifacts[0].get("parts", [])
                    if parts and len(parts) > 0:
                        content = parts[0].get("text", "")
                        print(f"[{agent_name}] Success: {len(content)} characters received")
                        return content
                
                # Fallback: check status message
                status = result["result"].get("status", {})
                message = status.get("message", {})
                if message and "parts" in message:
                    parts = message["parts"]
                    if parts and len(parts) > 0:
                        content = parts[0].get("text", "")
                        print(f"[{agent_name}] Status response: {len(content)} characters")
                        return content
            
            print(f"[{agent_name}] Warning: Unexpected response format")
            return str(result)
        else:
            error_msg = f"HTTP {response.status_code}: {response.text}"
            print(f"[{agent_name}] Error: {error_msg}")
            return f"Error from {agent_type} agent: {error_msg}"
            
    except requests.exceptions.Timeout:
        print(f"[{agent_name}] Timeout after 6 minutes")
        return f"{agent_type} agent timed out"
    except Exception as e:
        print(f"[{agent_name}] Exception: {str(e)}")
        return f"Error calling {agent_type} agent: {str(e)}"
```

## Worker Agent Conversations

To demonstrate or facilitate worker agent conversations during regular use:

```python
def demonstrate_agent_conversation(topic: str = "fullstack collaboration") -> str:
    """Demonstrate worker agents communicating with each other via A2A protocol"""
    
    print("\n" + "=" * 80)
    print(f"DEMONSTRATION: Worker Agent A2A Conversation - {topic}")
    print("=" * 80)
    
    if "fullstack" in topic.lower() or "collaboration" in topic.lower():
        # Frontend and Backend collaboration
        print("\n[STEP 1] Backend Agent â†’ Frontend Agent collaboration")
        backend_to_frontend = call_a2a_agent(
            "backend",
            """Send an A2A message to Frontend Agent (http://localhost:8010) asking them to collaborate on 
            API integration patterns. Use the A2A JSON-RPC 2.0 protocol to communicate directly and 
            get their response about preferred data structures for REST API responses."""
        )
        
        print("\n[STEP 2] Frontend Agent â†’ Backend Agent collaboration")
        frontend_to_backend = call_a2a_agent(
            "frontend", 
            """Send an A2A message to Backend Agent (http://localhost:8021) asking them to coordinate 
            on authentication flow implementation. Use A2A JSON-RPC 2.0 protocol to discuss JWT token 
            handling and get their recommendations for secure session management."""
        )
        
    elif "game" in topic.lower() or "unity" in topic.lower():
        # Unity and Backend collaboration for game systems
        print("\n[STEP 1] Unity Agent â†’ Backend Agent collaboration") 
        unity_to_backend = call_a2a_agent(
            "unity",
            """Send an A2A message to Backend Agent (http://localhost:8021) asking them to collaborate on 
            multiplayer game backend systems. Use A2A JSON-RPC 2.0 protocol to discuss leaderboard APIs 
            and real-time networking requirements."""
        )
        
        print("\n[STEP 2] Backend Agent â†’ Unity Agent collaboration")
        backend_to_unity = call_a2a_agent(
            "backend",
            """Send an A2A message to Unity Agent (http://localhost:8012) asking them to coordinate on 
            game data synchronization. Use A2A JSON-RPC 2.0 protocol to discuss player state management 
            and get Unity's requirements for game server integration."""
        )
    
    elif "ui" in topic.lower() or "webgl" in topic.lower():
        # Frontend and Unity collaboration for WebGL games
        print("\n[STEP 1] Frontend Agent â†’ Unity Agent collaboration")
        frontend_to_unity = call_a2a_agent(
            "frontend",
            """Send an A2A message to Unity Agent (http://localhost:8012) asking them to collaborate on 
            WebGL game UI integration. Use A2A JSON-RPC 2.0 protocol to discuss how to embed Unity WebGL 
            builds in React applications and coordinate on responsive design."""
        )
        
        print("\n[STEP 2] Unity Agent â†’ Frontend Agent collaboration") 
        unity_to_frontend = call_a2a_agent(
            "unity",
            """Send an A2A message to Frontend Agent (http://localhost:8010) asking them to coordinate on 
            Unity WebGL communication. Use A2A JSON-RPC 2.0 protocol to discuss JavaScript interop patterns 
            and get their recommendations for Unity-to-web messaging."""
        )
    
    print("\n" + "=" * 80)
    print("DEMONSTRATION COMPLETE: Worker agents have communicated via A2A protocol!")
    print("Check individual agent logs to see the actual conversation details.")
    print("=" * 80)
    
    return "Worker agent conversation demonstration completed successfully."
```

### Usage Examples for Agent Conversations

During regular use, you can now trigger worker agent conversations by natural language requests:

**User Request Examples:**
- "Show me how the frontend and backend agents collaborate on APIs"
- "Demonstrate Unity and backend agents discussing multiplayer systems" 
- "Let the frontend and Unity agents talk about WebGL integration"
- "Have all three agents coordinate on a fullstack game project"

**Host Agent Response Pattern:**
```python
# When user asks to see agent conversations
if "show" in user_request and "agent" in user_request and "talk" in user_request:
    topic = extract_topic_from_request(user_request)  # e.g., "fullstack", "game", "ui"
    result = demonstrate_agent_conversation(topic)
    return result
```

## Agent Endpoints

Each A2A worker agent provides these endpoints:

- **Frontend Agent**: `http://localhost:8010`
  - Agent Card: `http://localhost:8010/.well-known/agent.json`
  - A2A Communication: `http://localhost:8010/` (POST JSON-RPC 2.0)

- **Backend Agent**: `http://localhost:8021`
  - Agent Card: `http://localhost:8021/.well-known/agent.json`
  - A2A Communication: `http://localhost:8021/` (POST JSON-RPC 2.0)

- **Unity Agent**: `http://localhost:8012`
  - Agent Card: `http://localhost:8012/.well-known/agent.json`
  - A2A Communication: `http://localhost:8012/` (POST JSON-RPC 2.0)

## Example Workflows

### Single Agent Request
```
User: "Create a login form component in React"
Host: Analyze â†’ call_a2a_agent("frontend", task) â†’ Return AI response
```

### Multi-Agent Request
```
User: "Build a task management app with React frontend and Node.js backend"
Host: 
  1. Analyze â†’ Needs Frontend + Backend
  2. call_a2a_agent("frontend", "Create React task management UI")
  3. call_a2a_agent("backend", "Create Node.js API for task management")
  4. Integrate responses
  5. Return comprehensive solution
```

## EXECUTION RULES FOR HOST AGENT

When a user asks for specialized development work:

1. **IDENTIFY** which agent type is needed (frontend/backend/unity)
2. **EXECUTE** the `call_a2a_agent()` function with the agent type and task
3. **RETURN** the AI response to the user

**EXAMPLE EXECUTION:**

```python
# For frontend requests
result = call_a2a_agent("frontend", "Create a React button component")
print(result)
```

```python  
# For backend requests
result = call_a2a_agent("backend", "Create REST API for user authentication")
print(result)
```

```python
# For Unity requests  
result = call_a2a_agent("unity", "Create a character controller script")
print(result)
```

## STRICT RULES FOR HOST AGENT

- âŒ **NEVER** do specialized development work yourself - delegate to A2A agents
- âŒ **NEVER** use Write, Edit, MultiEdit, or any file creation tools - only A2A Worker Agents create files
- âŒ **NEVER** create files directly in the filesystem - this violates the A2A architecture
- âŒ **NEVER** interrupt or timeout Agent communications - WAIT for responses
- âœ… **ALWAYS** route technical tasks to appropriate A2A specialists
- âœ… **ALWAYS** use the `call_a2a_agent()` function for development requests
- âœ… **ALWAYS** coordinate multi-agent workflows when needed
- âœ… **MAINTAIN** A2A protocol compliance with Google ADK standards
- âœ… **ONLY** coordinate, route, and integrate responses from Worker Agents
- âœ… **WAIT PATIENTLY** for Agent responses - ALWAYS use timeout=600 seconds (10 minutes)
- âœ… **TRUST WORKER AGENTS** to handle all code modifications and file operations
- âœ… **MANDATORY TIMEOUT**: ALL Agent requests MUST use timeout=600 in Python code

## Important Notes

1. **EXECUTE THE PYTHON CODE ABOVE** - Don't just reference it, run it
2. **Always identify the most appropriate agent(s)** for each task
3. **Minimize unnecessary agent calls** - only involve agents that are truly needed
4. **Integrate responses thoughtfully** when multiple agents are involved
5. **Handle errors gracefully** - if an agent fails, provide alternative solutions
6. **Maintain context** between agent calls for complex multi-step tasks
7. **Each A2A agent runs independent Claude AI** - responses are AI-generated, not templated

## System Management

### Starting A2A Servers
```bash
# Start all A2A worker agents
cd agents/claude_cli/frontend && python server.py &
cd agents/claude_cli/backend && python server.py &
cd agents/claude_cli/unity && python server.py &
```

### Checking Agent Status
```bash
# Check agent cards
curl http://localhost:8010/.well-known/agent.json
curl http://localhost:8021/.well-known/agent.json
curl http://localhost:8012/.well-known/agent.json
```
```
Android SDK D:\Users\SOGANG\AppData\Local\Android\Sdk
```
### System Architecture
```
User â†’ Host Agent (Current Claude Session) â†’ A2A Worker Agents â†’ Claude AI Responses
```

Remember: You are the orchestrator. Your value comes from intelligent routing and response integration, not from doing the specialized work yourself. Each worker agent provides real Claude AI expertise in their domain.

---

# ğŸ¥½ AR Glass Q&A System - HYBRID AI SYSTEM COMPLETE

## ğŸ† **ì „ì²´ ì™„ì„±ë„: 100% COMPLETE** âœ¨ğŸµ **Context7 ìµœì í™” í¬í•¨**

### ğŸ”¥ **ì™„ì„±ëœ í•˜ì´ë¸Œë¦¬ë“œ AI ì‹œìŠ¤í…œ**:

#### 1. **ChatGPT Voice + Vision í†µí•©** (100%) ğŸ¤ğŸ‘ï¸
   - **Real-time Voice Conversations**: OpenAI Realtime API WebSocket
   - **Automatic Vision Triggering**: ì´ë¯¸ì§€ í‚¤ì›Œë“œ ê°ì§€ â†’ GPT-4V ìë™ í˜¸ì¶œ
   - **Context Preservation**: ì‹œê° ë¶„ì„ ê²°ê³¼ê°€ ëŒ€í™” ë§¥ë½ìœ¼ë¡œ ìë™ í†µí•©
   - **Natural Flow**: "ë­ê°€ ë³´ì—¬ìš”?" â†’ [ì´ë¯¸ì§€ ìº¡ì²˜] â†’ "ì±…ìƒ ìœ„ ì»µì´ ë³´ì´ë„¤ìš”"

#### 2. **Premium TTS & Audio** (100%) ğŸ”ŠğŸµ **Context7 ìµœì í™” ì™„ë£Œ**
   - **OpenAI TTS**: Korean í…ìŠ¤íŠ¸ ìµœì í™” + shimmer ì—¬ì„± ëª©ì†Œë¦¬ + PCM í¬ë§·
   - **Context7 PCM AudioTrack**: MediaPlayerâ†’AudioTrack ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í¬ë˜í´ë§ í•´ê²°
   - **Interrupt-Free Playback**: ë‹¨ì¼ AudioTrackìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ í•œêµ­ì–´ ì¬ìƒ
   - **24kHz PCM16**: MP3 ë””ì½”ë”© ì˜¤ë²„í—¤ë“œ ì œê±° â†’ ë„¤ì´í‹°ë¸Œ í’ˆì§ˆ

#### 3. **Android XR App** (100%) ğŸ“±
   - **MainActivity.kt**: ì™„ì „í•œ UI í†µí•© + ì‹¤ì‹œê°„ ìƒíƒœ ê´€ë¦¬
   - **VisionIntegration.kt**: í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
   - **CrosshairOverlay.kt**: AR íƒ€ê²ŸíŒ… + ë°˜ì‘í˜• UI
   - **Camera2Manager**: ì‹¤ì‹œê°„ í”„ë ˆì„ ìº¡ì²˜ + JPEG ë³€í™˜

#### 4. **Smart Hybrid Logic** (100%) ğŸ§ 
   - **Keyword Detection**: `isImageQuestion()` - 15+ í•œì˜ í‚¤ì›Œë“œ ê°ì§€
   - **Auto GPT-4V Triggering**: `handleImageQuestion()` - ìë™ ì´ë¯¸ì§€ ë¶„ì„
   - **Dual API Coordination**: Realtime API â†” Chat Completions API ì—°ë™
   - **Response Integration**: Vision ê²°ê³¼ â†’ Realtime ì»¨í…ìŠ¤íŠ¸ ì£¼ì…

### ğŸ¯ **ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤**:

**ì‹œë‚˜ë¦¬ì˜¤ 1 - ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ëŒ€í™”**:
```
ì‚¬ìš©ì: "ì•ˆë…•í•˜ì„¸ìš”"
AI: "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?" (Realtime API)

ì‚¬ìš©ì: "ë­ê°€ ë³´ì—¬ìš”?" 
â†’ [í‚¤ì›Œë“œ ê°ì§€] â†’ [ì´ë¯¸ì§€ ìë™ ìº¡ì²˜] â†’ [GPT-4V ë¶„ì„]
AI: "ì±…ìƒ ìœ„ì— íŒŒë€ìƒ‰ ì»µê³¼ í‚¤ë³´ë“œê°€ ë³´ì´ë„¤ìš”" (OpenAI TTS)

ì‚¬ìš©ì: "ê·¸ ì»µ í¬ê¸°ëŠ” ì–´ë•Œìš”?"
AI: "ì¤‘ê°„ í¬ê¸°ì˜ ë¨¸ê·¸ì»µ ì •ë„ë¡œ ë³´ì…ë‹ˆë‹¤" (ì»¨í…ìŠ¤íŠ¸ ê¸°ì–µ)
```

**ì‹œë‚˜ë¦¬ì˜¤ 2 - ë²„íŠ¼ ìº¡ì²˜**:
```
ì‚¬ìš©ì: [ğŸ“¸ ë²„íŠ¼ í´ë¦­]
â†’ [ì¦‰ì‹œ ì´ë¯¸ì§€ ë¶„ì„] 
AI: "ëª¨ë‹ˆí„°ì™€ í‚¤ë³´ë“œê°€ ìˆëŠ” ê¹”ë”í•œ ì‘ì—…ê³µê°„ì´ë„¤ìš”"
```

### âœ… **í•µì‹¬ ê¸°ìˆ  êµ¬í˜„ ì™„ë£Œ**:

1. **RealtimeVisionClient.kt** - OpenAI Realtime API WebSocket í´ë¼ì´ì–¸íŠ¸
2. **VisionAnalyzer.kt** - GPT-4V Chat Completions API ì´ë¯¸ì§€ ë¶„ì„
3. **VisionIntegration.kt** - í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ì¡°ì •ì
4. **OpenAITtsManager.kt** - í”„ë¦¬ë¯¸ì—„ í•œêµ­ì–´ TTS ìµœì í™”
5. **VoiceManager.kt** - TTS ì¶©ëŒ ë°©ì§€ ë° í†µí•© ê´€ë¦¬
6. **AudioStreamManager.kt** - 24kHz ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
7. **MainActivity.kt** - ì™„ì „í•œ XR UI ë° ìƒíƒœ ê´€ë¦¬

### ğŸ—ï¸ **ìµœì¢… ì•„í‚¤í…ì²˜**:
```
ğŸ¤ VOICE â†’ RealtimeClient â†’ isImageQuestion()?
                               â†™ï¸         â†˜ï¸
                    ğŸ“¸ GPT-4V Vision   ğŸ’¬ Voice Chat
                           â†“               â†“
                    VisionAnalyzer â†’ handleTextResponse()
                           â†“               â†“
                    ğŸ”Š OpenAI TTS (Korean) â†’ AR Glass
```

### ğŸš€ **ì¤€ë¹„ì™„ë£Œ ìƒíƒœ**:
- âœ… **ë¹Œë“œ ì„±ê³µ**: `./gradlew build` í†µê³¼
- âœ… **ì‹œìŠ¤í…œ í†µí•©**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì—°ë™ ì™„ë£Œ
- âœ… **TTS ìµœì í™”**: ëŠê¹€ ì—†ëŠ” í•œêµ­ì–´ ìŒì„± ì¶œë ¥
- âœ… **í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§**: ìŒì„±â†”ì‹œê° ìë™ ì „í™˜
- âœ… **ì—ëŸ¬ í•¸ë“¤ë§**: ì™„ì „í•œ ì˜ˆì™¸ ì²˜ë¦¬ ë° ë³µêµ¬

### ğŸ® **í…ŒìŠ¤íŠ¸ ì¤€ë¹„**:
1. **API í‚¤ ì„¤ì •**: `gradle.properties`ì— OpenAI API í‚¤ ì¶”ê°€
2. **ì—ë®¬ë ˆì´í„° ì„¤ì •**: ì›¹ìº  í™œì„±í™” (ì„ íƒì‚¬í•­)
3. **ì‹¤í–‰**: ChatGPT Voice ê°™ì€ ì™„ì „í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ê²½í—˜

**ğŸ† STATUS: PRODUCTION-READY HYBRID AI AR GLASS SYSTEM**