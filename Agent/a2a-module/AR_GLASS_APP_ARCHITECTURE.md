# ğŸ¥½ Google Glass AR Q&A App Architecture

## ğŸ¯ ì•± ê°œìš”
**ì‚¬ìš©ìê°€ AR Glassë¥¼ í†µí•´ ì‹¤ì„¸ê³„ ê°ì²´ë¥¼ ì‹­ìê°€ë¡œ íƒ€ê²ŸíŒ…í•˜ê³ , GPT-4Vì—ê²Œ ì§ˆë¬¸í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± ë‹µë³€ì„ ë°›ëŠ” ì‹œìŠ¤í…œ**

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Android XR    â”‚    â”‚   A2A Agents    â”‚    â”‚   Cloud APIs    â”‚
â”‚     Glass       â”‚    â”‚    (Local)      â”‚    â”‚    (Remote)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Camera2 API     â”‚â”€â”€â”€â–¶â”‚ Perception      â”‚    â”‚                 â”‚
â”‚ Crosshair UI    â”‚    â”‚ Agent :8030     â”‚    â”‚                 â”‚
â”‚ Voice Input     â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ TTS Output      â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                 â”‚
â”‚ XR Overlay      â”‚    â”‚ Vision Agent    â”‚â—„â”€â”€â–¶â”‚ GPT-4V Realtime â”‚
â”‚                 â”‚    â”‚ :8031           â”‚    â”‚ API             â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚                 â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                 â”‚
â”‚                 â”‚â—„â”€â”€â”€â”‚ UX/TTS Agent    â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚ :8032           â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚                 â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                 â”‚
â”‚                 â”‚    â”‚ Logger Agent    â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚ :8033           â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“± Android XR ì•± êµ¬ì¡°

### ğŸ¯ **MainActivity.kt ê°œì„ ì‚¬í•­**

```kotlin
class MainActivity : ComponentActivity() {
    // ğŸ” ê¶Œí•œ ê´€ë¦¬
    private val cameraPermissionLauncher = registerForActivityResult(
        ActivityResultContracts.RequestPermission()
    ) { isGranted ->
        if (isGranted) {
            initializeARSystem()
        } else {
            showPermissionRequiredMessage()
        }
    }
    
    private val microphonePermissionLauncher = registerForActivityResult(
        ActivityResultContracts.RequestPermission()
    ) { isGranted ->
        if (isGranted) {
            initializeVoiceSystem()
        }
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        // ê¶Œí•œ ìš”ì²­
        requestNecessaryPermissions()
        
        setContent {
            XRTESTTheme {
                val spatialConfiguration = LocalSpatialConfiguration.current
                if (LocalSpatialCapabilities.current.isSpatialUiEnabled) {
                    // ğŸ¥½ XR Glass ëª¨ë“œ
                    ARGlassContent(
                        onObjectQuery = { objectInfo, question ->
                            processObjectQuery(objectInfo, question)
                        }
                    )
                } else {
                    // ğŸ“± 2D í…ŒìŠ¤íŠ¸ ëª¨ë“œ
                    TestModeContent()
                }
            }
        }
    }
    
    private fun requestNecessaryPermissions() {
        cameraPermissionLauncher.launch(Manifest.permission.CAMERA)
        microphonePermissionLauncher.launch(Manifest.permission.RECORD_AUDIO)
    }
}
```

### ğŸ¯ **AR Glass UI ì»´í¬ë„ŒíŠ¸**

```kotlin
@Composable
fun ARGlassContent(
    onObjectQuery: (ObjectInfo, String) -> Unit
) {
    Box(modifier = Modifier.fillMaxSize()) {
        // ğŸ“¹ ì¹´ë©”ë¼ í”¼ë“œ ë°±ê·¸ë¼ìš´ë“œ (íˆ¬ëª…)
        CameraPreview(
            modifier = Modifier.fillMaxSize()
        )
        
        // ğŸ¯ ì‹­ìê°€ íƒ€ê²ŸíŒ… ì‹œìŠ¤í…œ
        CrosshairTargeting(
            modifier = Modifier.align(Alignment.Center),
            onTargetLocked = { objectInfo ->
                showTargetConfirmation(objectInfo)
            }
        )
        
        // ğŸ¤ ìŒì„± ì¸í„°í˜ì´ìŠ¤
        VoiceInterface(
            modifier = Modifier.align(Alignment.BottomCenter),
            onQuestionReceived = { question ->
                getCurrentTargetedObject()?.let { obj ->
                    onObjectQuery(obj, question)
                }
            }
        )
        
        // ğŸ“Š ìƒíƒœ í‘œì‹œê¸°
        SystemStatus(
            modifier = Modifier.align(Alignment.TopEnd)
        )
    }
}

@Composable
fun CrosshairTargeting(
    modifier: Modifier = Modifier,
    onTargetLocked: (ObjectInfo) -> Unit
) {
    var isLocked by remember { mutableStateOf(false) }
    
    Box(modifier = modifier) {
        // ì‹­ìê°€ í‘œì‹œ
        Icon(
            painter = painterResource(
                if (isLocked) R.drawable.ic_crosshair_locked 
                else R.drawable.ic_crosshair
            ),
            contentDescription = "Targeting Crosshair",
            modifier = Modifier.size(48.dp),
            tint = if (isLocked) Color.Green else Color.Red
        )
        
        // íƒ€ê²Ÿ í™•ì¸ ì• ë‹ˆë©”ì´ì…˜
        if (isLocked) {
            AnimatedTargetConfirmation()
        }
    }
}
```

---

## ğŸ“· Camera2 Integration

### ğŸ¥ **CameraManager.kt**

```kotlin
class ARCameraManager(
    private val context: Context,
    private val lifecycleOwner: LifecycleOwner
) {
    private var cameraDevice: CameraDevice? = null
    private var imageReader: ImageReader? = null
    private var backgroundThread: HandlerThread? = null
    private var backgroundHandler: Handler? = null
    
    // A2A ì—ì´ì „íŠ¸ í´ë¼ì´ì–¸íŠ¸
    private val perceptionAgent = A2AClient("http://localhost:8030")
    
    fun initializeCamera() {
        startBackgroundThread()
        openCamera()
    }
    
    private fun openCamera() {
        val manager = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            val cameraId = manager.cameraIdList[0]
            
            if (ActivityCompat.checkSelfPermission(context, Manifest.permission.CAMERA) 
                == PackageManager.PERMISSION_GRANTED) {
                
                manager.openCamera(cameraId, stateCallback, backgroundHandler)
            }
        } catch (e: CameraAccessException) {
            Log.e("ARCamera", "ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨", e)
        }
    }
    
    private val stateCallback = object : CameraDevice.StateCallback() {
        override fun onOpened(camera: CameraDevice) {
            cameraDevice = camera
            createCameraPreviewSession()
        }
        
        override fun onDisconnected(camera: CameraDevice) {
            camera.close()
            cameraDevice = null
        }
        
        override fun onError(camera: CameraDevice, error: Int) {
            camera.close()
            cameraDevice = null
        }
    }
    
    private fun createCameraPreviewSession() {
        try {
            // ImageReader ì„¤ì • (ROI ì¶”ì¶œìš©)
            imageReader = ImageReader.newInstance(1920, 1080, ImageFormat.JPEG, 1)
            imageReader?.setOnImageAvailableListener(onImageAvailableListener, backgroundHandler)
            
            // í”„ë¦¬ë·° ì„¸ì…˜ ìƒì„±
            val surfaces = listOf(imageReader?.surface)
            cameraDevice?.createCaptureSession(surfaces, sessionCallback, backgroundHandler)
            
        } catch (e: CameraAccessException) {
            Log.e("ARCamera", "í”„ë¦¬ë·° ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨", e)
        }
    }
    
    private val onImageAvailableListener = ImageReader.OnImageAvailableListener { reader ->
        val image = reader.acquireLatestImage()
        image?.let {
            // ğŸš€ A2A Perception Agentë¡œ í”„ë ˆì„ ì „ì†¡
            sendFrameToPerceptionAgent(it)
            it.close()
        }
    }
    
    private suspend fun sendFrameToPerceptionAgent(image: Image) {
        val imageBytes = convertImageToByteArray(image)
        
        val response = perceptionAgent.sendMessage(
            A2ARequest(
                method = "extract_crosshair_roi",
                params = mapOf(
                    "image_data" to imageBytes,
                    "crosshair_position" to "center",
                    "roi_size" to "320x320"
                )
            )
        )
        
        // ROI ë°ì´í„°ë¥¼ Vision Agentë¡œ ì „ë‹¬
        response.result?.let { roiData ->
            sendToVisionAgent(roiData)
        }
    }
}
```

---

## ğŸ¤ Voice Processing System

### ğŸ—£ï¸ **VoiceProcessor.kt**

```kotlin
class VoiceProcessor(private val context: Context) {
    private val speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
    private val textToSpeech = TextToSpeech(context) { status ->
        if (status == TextToSpeech.SUCCESS) {
            textToSpeech.language = Locale.getDefault()
        }
    }
    
    // A2A ì—ì´ì „íŠ¸ í´ë¼ì´ì–¸íŠ¸ë“¤
    private val visionAgent = A2AClient("http://localhost:8031")
    private val ttsAgent = A2AClient("http://localhost:8032")
    
    fun startListeningForQuestion() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, 
                    RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault())
            putExtra(RecognizerIntent.EXTRA_PROMPT, "ê°ì²´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...")
        }
        
        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                matches?.firstOrNull()?.let { question ->
                    processQuestion(question)
                }
            }
            
            override fun onError(error: Int) {
                Log.e("Voice", "ìŒì„± ì¸ì‹ ì˜¤ë¥˜: $error")
                speakError("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            }
            
            // ... ê¸°íƒ€ ì½œë°±ë“¤
        })
        
        speechRecognizer.startListening(intent)
    }
    
    private suspend fun processQuestion(question: String) {
        try {
            // ğŸ¤– Vision Agentë¡œ ì§ˆë¬¸ ì „ì†¡ (GPT-4V ì²˜ë¦¬)
            val visionResponse = visionAgent.sendMessage(
                A2ARequest(
                    method = "analyze_object_with_question",
                    params = mapOf(
                        "question" to question,
                        "roi_data" to getCurrentROI(),
                        "use_gpt4v_realtime" to true
                    )
                )
            )
            
            visionResponse.result?.let { answer ->
                // ğŸ”Š TTS Agentë¡œ ìŒì„± í•©ì„±
                synthesizeAndSpeak(answer.toString())
            }
            
        } catch (e: Exception) {
            Log.e("Voice", "ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨", e)
            speakError("ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        }
    }
    
    private suspend fun synthesizeAndSpeak(text: String) {
        try {
            val ttsResponse = ttsAgent.sendMessage(
                A2ARequest(
                    method = "synthesize_speech",
                    params = mapOf(
                        "text" to text,
                        "voice_style" to "natural",
                        "language" to "ko"
                    )
                )
            )
            
            // Android TTSë¡œ ì¬ìƒ
            textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, null)
            
        } catch (e: Exception) {
            // í´ë°±: ì§ì ‘ TTS ì‚¬ìš©
            textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, null)
        }
    }
    
    private fun speakError(message: String) {
        textToSpeech.speak(message, TextToSpeech.QUEUE_FLUSH, null, null)
    }
}
```

---

## ğŸŒ A2A Communication Layer

### ğŸ“¡ **A2AClient.kt**

```kotlin
data class A2ARequest(
    val jsonrpc: String = "2.0",
    val id: String = UUID.randomUUID().toString(),
    val method: String,
    val params: Map<String, Any>
)

data class A2AResponse(
    val jsonrpc: String,
    val id: String,
    val result: Any? = null,
    val error: A2AError? = null
)

data class A2AError(
    val code: Int,
    val message: String,
    val data: Any? = null
)

class A2AClient(private val baseUrl: String) {
    private val retrofit = Retrofit.Builder()
        .baseUrl(baseUrl)
        .addConverterFactory(GsonConverterFactory.create())
        .build()
    
    private val service = retrofit.create(A2AService::class.java)
    
    suspend fun sendMessage(request: A2ARequest): A2AResponse {
        return withContext(Dispatchers.IO) {
            try {
                val response = service.sendMessage(request)
                if (response.isSuccessful) {
                    response.body() ?: throw Exception("ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
                } else {
                    throw Exception("HTTP ${response.code()}: ${response.message()}")
                }
            } catch (e: Exception) {
                A2AResponse(
                    jsonrpc = "2.0",
                    id = request.id,
                    error = A2AError(
                        code = -1,
                        message = e.message ?: "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                    )
                )
            }
        }
    }
}

interface A2AService {
    @POST("/")
    suspend fun sendMessage(@Body request: A2ARequest): Response<A2AResponse>
}
```

---

## ğŸš€ ì‹¤í–‰ Flow

### 1. **ì•± ì‹œì‘**
```kotlin
1. ê¶Œí•œ ìš”ì²­ (ì¹´ë©”ë¼, ë§ˆì´í¬)
2. A2A ì—ì´ì „íŠ¸ ì—°ê²° í™•ì¸
3. Camera2 ì´ˆê¸°í™”
4. XR ì˜¤ë²„ë ˆì´ í™œì„±í™”
```

### 2. **ê°ì²´ íƒ€ê²ŸíŒ…**
```kotlin
1. ì¹´ë©”ë¼ í”¼ë“œ í‘œì‹œ
2. ì‹­ìê°€ ì¤‘ì•™ í‘œì‹œ
3. ì‚¬ìš©ìê°€ ê°ì²´ì— ì¡°ì¤€
4. íƒ€ê²Ÿ ë½ì˜¨ í‘œì‹œ
```

### 3. **ì§ˆë¬¸ ì²˜ë¦¬**
```kotlin
1. ìŒì„± ì¸ì‹ ì‹œì‘ ("ì´ê²Œ ë­ì•¼?")
2. Perception Agent â†’ ROI ì¶”ì¶œ
3. Vision Agent â†’ GPT-4V ë¶„ì„
4. TTS Agent â†’ ìŒì„± í•©ì„±
5. ìŠ¤í”¼ì»¤ ì¶œë ¥
```

---

## âš™ï¸ ì„¤ì • íŒŒì¼

### ğŸ“‹ **AndroidManifest.xml**
```xml
<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.INTERNET" />
<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" />

<uses-feature android:name="android.hardware.camera2" android:required="true" />
<uses-feature android:name="android.software.xr.immersive" android:required="false" />
```

### ğŸ”§ **build.gradle.kts**
```kotlin
dependencies {
    // ê¸°ì¡´ XR ì˜ì¡´ì„±ë“¤...
    
    // Camera2 API
    implementation("androidx.camera:camera-camera2:1.3.0")
    implementation("androidx.camera:camera-lifecycle:1.3.0")
    
    // ë„¤íŠ¸ì›Œí‚¹
    implementation("com.squareup.retrofit2:retrofit:2.9.0")
    implementation("com.squareup.retrofit2:converter-gson:2.9.0")
    
    // ê¶Œí•œ
    implementation("androidx.activity:activity-compose:1.8.0")
}
```

---

## ğŸ¯ **ë‹¤ìŒ êµ¬í˜„ ë‹¨ê³„**

1. âœ… **A2A ì—ì´ì „íŠ¸ ì¹´ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ**
2. âœ… **ê°€ìƒí™˜ê²½ ì„¤ì • ë° ê°€ì´ë“œ ì‘ì„± ì™„ë£Œ**
3. ğŸ”„ **MainActivityì— Camera2 ê¶Œí•œ ì¶”ê°€**
4. ğŸ”„ **CrosshairOverlay ì»´í¬ë„ŒíŠ¸ êµ¬í˜„**
5. ğŸ”„ **A2AClient í†µì‹  ë ˆì´ì–´ êµ¬í˜„**
6. ğŸ”„ **VoiceProcessor ìŒì„± ì²˜ë¦¬ êµ¬í˜„**
7. ğŸ”„ **GPT-4V Realtime API í‚¤ ì„¤ì •**

**ğŸš¨ ì¤‘ìš”: ëª¨ë“  ì‘ì—… ì „ì— ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•˜ì„¸ìš”!**