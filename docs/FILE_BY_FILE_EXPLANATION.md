# üìù ÌååÏùºÎ≥Ñ ÏÉÅÏÑ∏ ÏΩîÎìú ÏÑ§Î™Ö - ÏΩîÌãÄÎ¶∞ Ï¥àÎ≥¥ÏûêÏö©

## üéØ Ïù¥ Î¨∏ÏÑúÏùò Î™©Ï†Å
ÏΩîÌãÄÎ¶∞ÏùÑ Ïûò Î™®Î•¥Îäî Î∂ÑÎèÑ **Í∞Å ÌååÏùºÏù¥ Î¨¥ÏóáÏùÑ ÌïòÎäîÏßÄ** ÏâΩÍ≤å Ïù¥Ìï¥Ìï† Ïàò ÏûàÎèÑÎ°ù ÏÑ§Î™ÖÌï©ÎãàÎã§.

---

## 1Ô∏è‚É£ **MainActivity.kt** - Ïï±Ïùò ÏãúÏûëÏ†ê üöÄ

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- Ïï±Ïù¥ ÏºúÏßÄÎ©¥ **Í∞ÄÏû• Î®ºÏ†Ä Ïã§Ìñâ**ÎêòÎäî ÌååÏùº
- ÌôîÎ©¥ÏùÑ Í∑∏Î¶¨Í≥†, Í∂åÌïúÏùÑ ÏöîÏ≤≠ÌïòÍ≥†, Îã§Î•∏ Î™®Îì† ÏãúÏä§ÌÖúÏùÑ ÏãúÏûëÏãúÌÇ¥

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        // üì± Ïï±Ïù¥ ÏãúÏûëÎê† Îïå Ïã§ÌñâÎêòÎäî Ìï®Ïàò
        super.onCreate(savedInstanceState)
        setContent {
            // üé® ÌôîÎ©¥ UIÎ•º Í∑∏Î¶¨Í∏∞ ÏãúÏûë
            XRTESTTheme {
                if (LocalSpatialCapabilities.current.isSpatialUiEnabled) {
                    // ‚ú® VR/AR Î™®Îìú (3D ÌôîÎ©¥)
                    MySpatialContent()
                } else {
                    // üì± ÏùºÎ∞ò Î™®Îìú (ÌèâÎ©¥ ÌôîÎ©¥)  
                    My2DContent()
                }
            }
        }
    }
}
```

### **Ï£ºÏöî Ìï®ÏàòÎì§**:
- `onCreate()`: Ïï± ÏãúÏûëÌï† Îïå Ìïú Î≤à Ïã§Ìñâ
- `My2DContent()`: ÏùºÎ∞ò Ïä§ÎßàÌä∏Ìè∞ ÌôîÎ©¥ UI Í∑∏Î¶¨Í∏∞
- `MySpatialContent()`: VR/AR 3D Í≥µÍ∞Ñ UI Í∑∏Î¶¨Í∏∞

### **Ïó¨Í∏∞ÏÑú ÏãúÏûëÎêòÎäî Í≤ÉÎì§**:
1. Ïπ¥Î©îÎùº Îß§ÎãàÏ†Ä Ï¥àÍ∏∞Ìôî
2. ÏùåÏÑ± Îß§ÎãàÏ†Ä Ï¥àÍ∏∞Ìôî  
3. OpenAI ÎπÑÏ†Ñ ÌÜµÌï© ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
4. Í∂åÌïú ÏöîÏ≤≠ (Ïπ¥Î©îÎùº, ÎßàÏù¥ÌÅ¨)

---

## 2Ô∏è‚É£ **VisionIntegration.kt** - Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú ÏßÄÌúòÍ¥Ä üéØ

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **Î™®Îì† ÏãúÏä§ÌÖúÏùÑ ÌÜµÌï© Í¥ÄÎ¶¨**ÌïòÎäî ÌïµÏã¨ ÌååÏùº
- Ïπ¥Î©îÎùº + ÏùåÏÑ± + OpenAIÎ•º ÌïòÎÇòÎ°ú Ïó∞Í≤∞

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class VisionIntegration(
    private val context: Context,
    private val apiKey: String,           // OpenAI API ÌÇ§
    private val camera2Manager: Camera2Manager,  // Ïπ¥Î©îÎùº ÏãúÏä§ÌÖú
    private val voiceManager: VoiceManager       // ÏùåÏÑ± ÏãúÏä§ÌÖú
) {
    
    fun startSession() {
        // üîó OpenAIÏóê Ïó∞Í≤∞ ÏãúÏûë
        realtimeClient.connect()
        _state.value = IntegrationState.CONNECTING
    }
    
    fun sendQuery(question: String) {
        // üì∏ Ïπ¥Î©îÎùºÏóêÏÑú ÌòÑÏû¨ Ïù¥ÎØ∏ÏßÄ Í∞ÄÏ†∏Ïò§Í∏∞
        val currentFrame = camera2Manager.getCurrentFrame()
        
        // ü§ñ OpenAIÏóêÍ≤å Ïù¥ÎØ∏ÏßÄ + ÏßàÎ¨∏ Ï†ÑÏÜ°
        realtimeClient.sendImageWithPrompt(currentFrame, question)
        
        _state.value = IntegrationState.PROCESSING
    }
}
```

### **ÏÉÅÌÉú Í¥ÄÎ¶¨**:
```kotlin
enum class IntegrationState {
    IDLE,           // üò¥ ÎåÄÍ∏∞ Ï§ë
    CONNECTING,     // üîå OpenAI Ïó∞Í≤∞ Ï§ë
    READY,          // ‚úÖ Ï§ÄÎπÑ ÏôÑÎ£å
    LISTENING,      // üëÇ ÏùåÏÑ± ÏûÖÎ†• Í∏∞Îã§Î¶¨Îäî Ï§ë
    PROCESSING,     // ü§ñ AIÍ∞Ä ÏÉùÍ∞ÅÌïòÎäî Ï§ë
    RESPONDING,     // üí¨ AIÍ∞Ä ÎãµÎ≥ÄÌïòÎäî Ï§ë
    ERROR           // ‚ùå Ïò§Î•ò Î∞úÏÉù
}
```

### **Ïù¥ ÌååÏùºÏùò Ïó≠Ìï†**:
1. **ÌÜµÌï© Í¥ÄÎ¶¨**: Î™®Îì† ÏãúÏä§ÌÖúÏùÑ ÌïòÎÇòÎ°ú Ïó∞Í≤∞
2. **ÏÉÅÌÉú Ï∂îÏ†Å**: ÌòÑÏû¨ ÏãúÏä§ÌÖúÏù¥ Î≠ò ÌïòÍ≥† ÏûàÎäîÏßÄ Í¥ÄÎ¶¨
3. **Îç∞Ïù¥ÌÑ∞ Ï†ÑÎã¨**: Ïπ¥Î©îÎùº ‚Üí OpenAI ‚Üí ÏùåÏÑ± Ï∂úÎ†• Ïó∞Í≤∞

---

## 3Ô∏è‚É£ **RealtimeVisionClient.kt** - OpenAIÏôÄ ÎåÄÌôîÌïòÎäî Îã¥ÎãπÏûê ü§ñ

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **OpenAI GPT-4V APIÏôÄ Ïã§ÏãúÍ∞Ñ WebSocket ÌÜµÏã†**
- Ïù¥ÎØ∏ÏßÄ + ÏùåÏÑ±ÏùÑ Î≥¥ÎÇ¥Í≥†, AI ÎãµÎ≥ÄÏùÑ Î∞õÏïÑÏò¥

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class RealtimeVisionClient(
    private val apiKey: String,
    private val onAudioResponse: (ByteArray) -> Unit,  // ÏùåÏÑ± ÏùëÎãµ ÏΩúÎ∞±
    private val onTextResponse: (String) -> Unit,      // ÌÖçÏä§Ìä∏ ÏùëÎãµ ÏΩúÎ∞±
    private val onError: (String) -> Unit              // ÏóêÎü¨ ÏΩúÎ∞±
) {
    
    fun connect() {
        // üåê OpenAI ÏÑúÎ≤ÑÏóê WebSocket Ïó∞Í≤∞
        val request = Request.Builder()
            .url("wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17")
            .addHeader("Authorization", "Bearer $apiKey")
            .addHeader("OpenAI-Beta", "realtime=v1")
            .build()
        
        webSocket = client.newWebSocket(request, createWebSocketListener())
    }
    
    fun sendImageWithPrompt(imageData: ByteArray, prompt: String?) {
        // üì∏ Ïù¥ÎØ∏ÏßÄÎ•º Base64Î°ú Î≥ÄÌôò
        val base64Image = Base64.encodeToString(imageData, Base64.NO_WRAP)
        
        // üì§ OpenAIÏóêÍ≤å Ï†ÑÏÜ°Ìï† JSON Î©îÏãúÏßÄ ÎßåÎì§Í∏∞
        val event = JSONObject().apply {
            put("type", "conversation.item.create")
            put("item", JSONObject().apply {
                put("type", "message")
                put("role", "user")
                put("content", JSONArray().apply {
                    // Ïù¥ÎØ∏ÏßÄ Ï∂îÍ∞Ä
                    put(JSONObject().apply {
                        put("type", "input_image")
                        put("image", base64Image)
                    })
                    // ÌÖçÏä§Ìä∏ ÏßàÎ¨∏ Ï∂îÍ∞Ä
                    if (!prompt.isNullOrEmpty()) {
                        put(JSONObject().apply {
                            put("type", "input_text")
                            put("text", prompt)
                        })
                    }
                })
            })
        }
        
        // üöÄ Ï†ÑÏÜ°!
        sendEvent(event)
        requestResponse() // AIÏóêÍ≤å ÎãµÎ≥Ä ÏöîÏ≤≠
    }
}
```

### **Ïù¥Î≤§Ìä∏ Ï≤òÎ¶¨**:
```kotlin
private fun handleRealtimeEvent(event: JSONObject) {
    val type = event.getString("type")
    
    when (type) {
        "response.audio.delta" -> {
            // üîä ÏùåÏÑ± ÏùëÎãµ Ï°∞Í∞ÅÏù¥ ÎèÑÏ∞©Ìï®
            val delta = event.getString("delta")
            val audioData = Base64.decode(delta, Base64.DEFAULT)
            // ÏùåÏÑ± Ïû¨ÏÉù ÎåÄÍ∏∞Ïó¥Ïóê Ï∂îÍ∞Ä
        }
        
        "response.text.delta" -> {
            // üìù ÌÖçÏä§Ìä∏ ÏùëÎãµ Ï°∞Í∞ÅÏù¥ ÎèÑÏ∞©Ìï®
            val delta = event.getString("delta")
            onTextResponse(delta) // UIÏóê ÌÖçÏä§Ìä∏ ÌëúÏãú
        }
        
        "error" -> {
            // ‚ùå ÏóêÎü¨ Î∞úÏÉù
            val error = event.getJSONObject("error")
            val message = error.getString("message")
            onError(message)
        }
    }
}
```

### **Ïù¥ ÌååÏùºÏùò ÌïµÏã¨**:
1. **WebSocket Ïó∞Í≤∞**: OpenAIÏôÄ Ïã§ÏãúÍ∞Ñ ÏÜåÌÜµ
2. **Ïù¥ÎØ∏ÏßÄ Ï†ÑÏÜ°**: Ïπ¥Î©îÎùº ÏÇ¨ÏßÑÏùÑ AIÏóêÍ≤å Î≥¥ÎÉÑ
3. **ÏùëÎãµ ÏàòÏã†**: AIÏùò ÏùåÏÑ±+ÌÖçÏä§Ìä∏ ÎãµÎ≥Ä Î∞õÍ∏∞
4. **ÏóêÎü¨ Ï≤òÎ¶¨**: Ïó∞Í≤∞ ÎÅäÍπÄ, API Ïò§Î•ò Îì± Ï≤òÎ¶¨

---

## 4Ô∏è‚É£ **AudioStreamManager.kt** - Í≥†ÌíàÏßà ÏùåÏÑ± Ï≤òÎ¶¨ üîä

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **24kHz Í≥†ÌíàÏßà ÏùåÏÑ±** ÎÖπÏùå Î∞è Ïû¨ÏÉù
- OpenAI APIÏóê ÎßûÎäî Ï†ïÌôïÌïú ÏùåÏÑ± Ìè¨Îß∑ Ï≤òÎ¶¨

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class AudioStreamManager(
    private val onAudioCaptured: (ByteArray) -> Unit
) {
    companion object {
        private const val SAMPLE_RATE = 24000      // 24kHz (OpenAI ÏöîÍµ¨ÏÇ¨Ìï≠)
        private const val CHANNEL_CONFIG_RECORD = AudioFormat.CHANNEL_IN_MONO
        private const val CHANNEL_CONFIG_PLAY = AudioFormat.CHANNEL_OUT_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT  // 16ÎπÑÌä∏
    }
    
    fun startRecording() {
        // üé§ ÎßàÏù¥ÌÅ¨ÏóêÏÑú 24kHzÎ°ú ÎÖπÏùå ÏãúÏûë
        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            SAMPLE_RATE,
            CHANNEL_CONFIG_RECORD,
            AUDIO_FORMAT,
            bufferSize
        )
        
        audioRecord?.startRecording()
        
        // üîÑ Î≥ÑÎèÑ Ïä§Î†àÎìúÏóêÏÑú Í≥ÑÏÜç ÎÖπÏùå
        recordingJob = coroutineScope.launch {
            while (isRecording) {
                val buffer = ByteArray(bufferSize)
                val bytesRead = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                
                if (bytesRead > 0) {
                    // üìä ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Î∞è ÏùåÎüâ Ï†ïÍ∑úÌôî
                    val processedAudio = processAudioInput(buffer)
                    onAudioCaptured(processedAudio)
                }
            }
        }
    }
    
    fun playAudio(audioData: ByteArray) {
        // üîä 24kHz ÏùåÏÑ±ÏùÑ Ïä§ÌîºÏª§Î°ú Ïû¨ÏÉù
        audioTrack = AudioTrack(
            AudioManager.STREAM_MUSIC,
            SAMPLE_RATE,
            CHANNEL_CONFIG_PLAY,
            AUDIO_FORMAT,
            audioData.size,
            AudioTrack.MODE_STREAM
        )
        
        audioTrack?.play()
        audioTrack?.write(audioData, 0, audioData.size)
    }
}
```

### **ÏùåÏÑ± Ï≤òÎ¶¨ Í≥ºÏ†ï**:
1. **ÎÖπÏùå**: ÎßàÏù¥ÌÅ¨ ‚Üí 24kHz PCM16 ÌòïÏãù
2. **ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞**: Î∞∞Í≤Ω ÏÜåÏùå ÌïÑÌÑ∞ÎßÅ
3. **Ï†ïÍ∑úÌôî**: ÏùåÎüâ Ï†ÅÏ†ï ÏàòÏ§ÄÏúºÎ°ú Ï°∞Ï†ï
4. **Ï†ÑÏÜ°**: OpenAIÏóêÍ≤å Base64Î°ú Ïù∏ÏΩîÎî©Ìï¥ÏÑú Ï†ÑÏÜ°
5. **ÏàòÏã†**: OpenAIÏóêÏÑú 24kHz ÏùåÏÑ± ÏùëÎãµ Î∞õÍ∏∞
6. **Ïû¨ÏÉù**: Ïä§ÌîºÏª§Î°ú Í≥†ÌíàÏßà ÏùåÏÑ± Ï∂úÎ†•

---

## 5Ô∏è‚É£ **Camera2Manager.kt** - Ïπ¥Î©îÎùº Ï†ÑÎ¨∏Í∞Ä üì∑

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **Android Camera2 APIÎ°ú Ïπ¥Î©îÎùº Ï†úÏñ¥**
- Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÏÇ¨ÏßÑÏùÑ Ï∞çÏñ¥ÏÑú AI Î∂ÑÏÑùÏö©ÏúºÎ°ú Ï†úÍ≥µ

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class Camera2Manager(private val context: Context) {
    
    fun startCamera() {
        // üì∑ Ïπ¥Î©îÎùº Îß§ÎãàÏ†Ä Í∞ÄÏ†∏Ïò§Í∏∞
        val cameraManager = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        
        try {
            // üìã ÌõÑÎ©¥ Ïπ¥Î©îÎùº Ï∞æÍ∏∞
            val cameraId = cameraManager.cameraIdList.first { id ->
                val characteristics = cameraManager.getCameraCharacteristics(id)
                characteristics.get(CameraCharacteristics.LENS_FACING) == 
                    CameraCharacteristics.LENS_FACING_BACK
            }
            
            // üîß Ïπ¥Î©îÎùº ÏÑ§Ï†ï
            cameraManager.openCamera(cameraId, cameraDeviceCallback, backgroundHandler)
            
        } catch (e: Exception) {
            Log.e(TAG, "Camera initialization failed: ${e.message}")
        }
    }
    
    private fun createCameraPreviewSession() {
        // üì∏ Ïó∞ÏÜç ÏÇ¨ÏßÑ Ï¥¨ÏòÅÏùÑ ÏúÑÌïú ÏÑ∏ÏÖò ÎßåÎì§Í∏∞
        val reader = ImageReader.newInstance(
            PREVIEW_WIDTH,    // 1920ÌîΩÏÖÄ
            PREVIEW_HEIGHT,   // 1080ÌîΩÏÖÄ  
            ImageFormat.JPEG, // JPEG Ìè¨Îß∑
            2                 // ÏµúÎåÄ 2Ïû• Î≤ÑÌçº
        )
        
        reader.setOnImageAvailableListener({ reader ->
            // üì∏ ÏÉà ÏÇ¨ÏßÑÏù¥ Ï∞çÌûê ÎïåÎßàÎã§ Ïã§Ìñâ
            val image = reader.acquireLatestImage()
            processFrame(image) // Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨
            image.close()
        }, backgroundHandler)
    }
    
    private fun processFrame(image: Image) {
        // üñºÔ∏è Ïù¥ÎØ∏ÏßÄÎ•º JPEG Î∞îÏù¥Ìä∏ Î∞∞Ïó¥Î°ú Î≥ÄÌôò
        val buffer = image.planes[0].buffer
        val bytes = ByteArray(buffer.remaining())
        buffer.get(bytes)
        
        // üìè Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï°∞Ï†ï (OpenAI ÏöîÍµ¨ÏÇ¨Ìï≠: ÏµúÎåÄ 1024x1024)
        val resizedBytes = resizeImageForAPI(bytes)
        
        // üì§ VisionIntegrationÏóêÍ≤å Ï†ÑÎã¨
        onFrameProcessed(resizedBytes)
    }
}
```

### **Ïπ¥Î©îÎùº ÏûëÏóÖ ÏàúÏÑú**:
1. **Í∂åÌïú ÌôïÏù∏**: Ïπ¥Î©îÎùº ÏÇ¨Ïö© Í∂åÌïú Ï≤¥ÌÅ¨
2. **Ïπ¥Î©îÎùº Ïó¥Í∏∞**: ÌõÑÎ©¥ Ïπ¥Î©îÎùº ÌôúÏÑ±Ìôî
3. **ÌîÑÎ¶¨Î∑∞ ÏãúÏûë**: Ïã§ÏãúÍ∞Ñ ÏòÅÏÉÅ ÌëúÏãú
4. **ÏûêÎèô Ï¥¨ÏòÅ**: 1Ï¥àÎßàÎã§ ÏÇ¨ÏßÑ Ï¥¨ÏòÅ
5. **Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨**: ÌÅ¨Í∏∞ Ï°∞Ï†ï, Ìè¨Îß∑ Î≥ÄÌôò
6. **Ï†ÑÎã¨**: VisionIntegrationÏúºÎ°ú Ïù¥ÎØ∏ÏßÄ Ï†ÑÏÜ°

---

## 6Ô∏è‚É£ **VoiceManager.kt** - ÏùåÏÑ± Ïù∏Ïãù Ï†ÑÎ¨∏Í∞Ä üé§

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò** (Speech-to-Text)
- **ÌÖçÏä§Ìä∏Î•º ÏùåÏÑ±ÏúºÎ°ú Î≥ÄÌôò** (Text-to-Speech) - Î∞±ÏóÖÏö©

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
class VoiceManager(private val context: Context) {
    
    private var speechRecognizer: SpeechRecognizer? = null
    private var textToSpeech: TextToSpeech? = null
    
    fun startListening() {
        // üéß ÏùåÏÑ± Ïù∏Ïãù ÏãúÏûë
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
        
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, 
                    RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault())
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true) // Ïã§ÏãúÍ∞Ñ Í≤∞Í≥º
        }
        
        speechRecognizer?.setRecognitionListener(object : RecognitionListener {
            override fun onResults(results: Bundle?) {
                // ‚úÖ ÏùåÏÑ± Ïù∏Ïãù ÏôÑÎ£å!
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                if (!matches.isNullOrEmpty()) {
                    val recognizedText = matches[0]
                    _recognizedText.value = recognizedText
                    Log.d(TAG, "Recognized: $recognizedText")
                }
            }
            
            override fun onError(error: Int) {
                // ‚ùå ÏùåÏÑ± Ïù∏Ïãù Ïã§Ìå®
                Log.e(TAG, "Speech recognition error: $error")
                _recognizedText.value = null
            }
        })
        
        speechRecognizer?.startListening(intent)
    }
    
    fun speak(text: String) {
        // üó£Ô∏è ÌÖçÏä§Ìä∏Î•º ÏùåÏÑ±ÏúºÎ°ú Î≥ÄÌôò (Î∞±ÏóÖÏö©)
        textToSpeech?.speak(
            text,
            TextToSpeech.QUEUE_FLUSH, // Ïù¥Ï†Ñ ÏùåÏÑ± Ï§ëÎã®ÌïòÍ≥† ÏÉàÎ°ú Ïû¨ÏÉù
            null,
            "utteranceId"
        )
    }
}
```

### **ÏùåÏÑ± Ï≤òÎ¶¨ ÌùêÎ¶Ñ**:
1. **Îì£Í∏∞ ÏãúÏûë**: `startListening()` Ìò∏Ï∂ú
2. **ÏùåÏÑ± ÏàòÏã†**: ÎßàÏù¥ÌÅ¨Î°ú ÏÇ¨Ïö©Ïûê ÏùåÏÑ± ÏûÖÎ†•
3. **ÌÖçÏä§Ìä∏ Î≥ÄÌôò**: "Ïù¥Í≤å Î≠êÏïº?" ‚Üí ÌÖçÏä§Ìä∏
4. **Í≤∞Í≥º Ï†ÑÎã¨**: MainActivityÏóêÏÑú Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏ Í∞êÏßÄ
5. **ÏßàÎ¨∏ Ï†ÑÏÜ°**: VisionIntegration.sendQuery() Ìò∏Ï∂ú

---

## 7Ô∏è‚É£ **CrosshairOverlay.kt** - Ïã≠ÏûêÍ∞Ä UI üéØ

### **Ïù¥ ÌååÏùºÏù¥ ÌïòÎäî Ïùº**:
- **ÌôîÎ©¥ Ï§ëÏïôÏóê Ïã≠ÏûêÍ∞Ä ÌëúÏãú**
- ÏãúÏä§ÌÖú ÏÉÅÌÉúÏóê Îî∞Îùº ÏÉâÏÉÅÍ≥º Ïï†ÎãàÎ©îÏù¥ÏÖò Î≥ÄÍ≤Ω

### **ÌïµÏã¨ ÏΩîÎìú Î∂ÄÎ∂Ñ**:
```kotlin
@Composable
fun CrosshairOverlay(
    isActive: Boolean = true,
    isTargeting: Boolean = false,
    modifier: Modifier = Modifier
) {
    Box(modifier = modifier) {
        if (isActive) {
            // ‚äï Ïã≠ÏûêÍ∞Ä Í∑∏Î¶¨Í∏∞
            Canvas(
                modifier = Modifier
                    .size(60.dp)
                    .align(Alignment.Center)
            ) {
                val crosshairColor = when {
                    isTargeting -> Color(0xFFFFA500)  // üü† Ï£ºÌô©ÏÉâ (Ï≤òÎ¶¨ Ï§ë)
                    else -> Color.White               // ‚ö™ Ìù∞ÏÉâ (ÎåÄÍ∏∞)
                }
                
                val strokeWidth = 3.dp.toPx()
                val crossSize = 30.dp.toPx()
                
                // ÏÑ∏Î°úÏÑ† Í∑∏Î¶¨Í∏∞
                drawLine(
                    color = crosshairColor,
                    start = Offset(center.x, center.y - crossSize/2),
                    end = Offset(center.x, center.y + crossSize/2),
                    strokeWidth = strokeWidth
                )
                
                // Í∞ÄÎ°úÏÑ† Í∑∏Î¶¨Í∏∞  
                drawLine(
                    color = crosshairColor,
                    start = Offset(center.x - crossSize/2, center.y),
                    end = Offset(center.x + crossSize/2, center.y),
                    strokeWidth = strokeWidth
                )
                
                // Í∞ÄÏö¥Îç∞ Ï†ê
                drawCircle(
                    color = crosshairColor,
                    radius = 4.dp.toPx(),
                    center = center
                )
            }
        }
    }
}
```

### **Ïã≠ÏûêÍ∞Ä ÏÉÅÌÉú**:
- **‚ö™ Ìù∞ÏÉâ**: ÎåÄÍ∏∞ ÏÉÅÌÉú - "Ï°∞Ï§ÄÌïòÍ≥† ÏßàÎ¨∏ÌïòÏÑ∏Ïöî"
- **üü† Ï£ºÌô©ÏÉâ**: Ï≤òÎ¶¨ Ï§ë - "AIÍ∞Ä Î∂ÑÏÑùÌïòÍ≥† ÏûàÏñ¥Ïöî"
- **üî¥ Îπ®Í∞ÑÏÉâ**: ÏóêÎü¨ ÏÉÅÌÉú - "Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌñàÏñ¥Ïöî"

---

## üåê **ÎÑ§Ìä∏ÏõåÌÅ¨ ÌååÏùºÎì§**

### **A2AClient.kt** - Agent ÌÜµÏã† Îã¥ÎãπÏûê
```kotlin
// Îã§Î•∏ AgentÎì§(Perception, UX/TTS, Logger)Í≥º HTTPÎ°ú ÌÜµÏã†
class A2AClient {
    suspend fun sendMessage(agentPort: Int, message: String): String {
        // HTTP POSTÎ°ú JSON-RPC 2.0 Î©îÏãúÏßÄ Ï†ÑÏÜ°
    }
}
```

### **A2AModels.kt** - Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ï†ïÏùò
```kotlin
// Agent Í∞Ñ ÌÜµÏã†Ïóê ÏÇ¨Ïö©Ìï† Îç∞Ïù¥ÌÑ∞ ÌòïÏãùÎì§
data class A2AMessage(
    val messageId: String,
    val taskId: String,
    val contextId: String,
    val parts: List<A2APart>
)
```

---

## ‚öôÔ∏è **ÏÑ§Ï†ï ÌååÏùºÎì§**

### **build.gradle.kts** - ÎπåÎìú ÏÑ§Ï†ï
```kotlin
dependencies {
    // üì∑ Ïπ¥Î©îÎùº ÎùºÏù¥Î∏åÎü¨Î¶¨
    implementation("androidx.camera:camera-camera2:1.4.0")
    
    // üåê ÎÑ§Ìä∏ÏõåÌÅ¨ ÎùºÏù¥Î∏åÎü¨Î¶¨  
    implementation("com.squareup.okhttp3:okhttp:4.12.0")
    
    // üîê JSON Ï≤òÎ¶¨
    implementation("org.json:json:20230618")
    
    // OpenAI API ÌÇ§ ÏÑ§Ï†ï
    buildConfigField("String", "OPENAI_API_KEY", "\"${project.findProperty("OPENAI_API_KEY")}\"")
}
```

### **AndroidManifest.xml** - Í∂åÌïú ÏÑ§Ï†ï
```xml
<!-- üì∑ Ïπ¥Î©îÎùº Í∂åÌïú -->
<uses-permission android:name="android.permission.CAMERA" />

<!-- üé§ ÎßàÏù¥ÌÅ¨ Í∂åÌïú -->
<uses-permission android:name="android.permission.RECORD_AUDIO" />

<!-- üåê Ïù∏ÌÑ∞ÎÑ∑ Í∂åÌïú -->
<uses-permission android:name="android.permission.INTERNET" />
```

---

## üöÄ **Ï†ÑÏ≤¥ Ïã§Ìñâ ÌùêÎ¶Ñ ÏöîÏïΩ**

1. **MainActivity** ‚Üí Ïï± ÏãúÏûë, UI Í∑∏Î¶¨Í∏∞
2. **Í∂åÌïú ÏöîÏ≤≠** ‚Üí Ïπ¥Î©îÎùº, ÎßàÏù¥ÌÅ¨ Í∂åÌïú
3. **VisionIntegration** ‚Üí Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
4. **RealtimeVisionClient** ‚Üí OpenAI Ïó∞Í≤∞
5. **ÎåÄÍ∏∞ ÏÉÅÌÉú** ‚Üí LISTENING, Ïã≠ÏûêÍ∞Ä Ìù∞ÏÉâ
6. **ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏** ‚Üí VoiceManager ÏùåÏÑ± Ïù∏Ïãù
7. **Ïù¥ÎØ∏ÏßÄ Ï∫°Ï≤ò** ‚Üí Camera2Manager ÏÇ¨ÏßÑ Ï¥¨ÏòÅ  
8. **AI ÏöîÏ≤≠** ‚Üí Ïù¥ÎØ∏ÏßÄ+ÌÖçÏä§Ìä∏Î•º OpenAIÏóê Ï†ÑÏÜ°
9. **AI ÏùëÎãµ** ‚Üí 24kHz ÏùåÏÑ±ÏúºÎ°ú ÎãµÎ≥Ä ÏàòÏã†
10. **ÏùåÏÑ± Ïû¨ÏÉù** ‚Üí AudioStreamManagerÎ°ú Í≥†ÌíàÏßà Ïû¨ÏÉù
11. **ÏôÑÎ£å** ‚Üí Îã§Ïãú LISTENING ÏÉÅÌÉúÎ°ú

**Ïù¥Ï†ú Í∞Å ÌååÏùºÏù¥ Î¨¥ÏóáÏùÑ ÌïòÎäîÏßÄ ÏôÑÏ†ÑÌûà Ïù¥Ìï¥ÌïòÏÖ®ÎÇòÏöî? üéØ**